from tinydb import TinyDB, Query

from src.modules.event.event_detect import detect_anomalies_realtime

def monitoring_event_detect(monitor_db: TinyDB, prism_core_db, start: str, end: str, task_id: str,
                           target_file: str = None, target_process: str = None, user_query: str = None):
    """
    ëª¨ë‹ˆí„°ë§ ì´ë²¤íŠ¸ ê°ì§€ í•¨ìˆ˜

    Args:
        monitor_db: ëª¨ë‹ˆí„° DB
        prism_core_db: PRISM Core DB
        start: ì‹œì‘ ì‹œê°„ (ISO format)
        end: ì¢…ë£Œ ì‹œê°„ (ISO format)
        task_id: íƒœìŠ¤í¬ ID
        target_process: íƒ€ê²Ÿ ê³µì • (ì˜ˆ: 'semi_cmp_sensors') - ì§ì ‘ ì§€ì • ì‹œ ì‚¬ìš©
        user_query: ì‚¬ìš©ì ì¿¼ë¦¬ - query_decomposeë¡œ ê³µì • ìë™ íŒë³„ ì‹œ ì‚¬ìš©

    Returns:
        ì´ë²¤íŠ¸ ê°ì§€ ê²°ê³¼
    """
    classified_process = None

    # 1. user_queryê°€ ìˆë‹¤ë©´ query_decomposeë¡œ ê³µì • ìë™ íŒë³„ (í–¥í›„ ê¸°ëŠ¥)
    if user_query and not target_process:
        try:
            # âš ï¸ query_decomposeê°€ classified_classë¥¼ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •ëœ í›„ í™œì„±í™”
            # from prism_monitor.modules.query_decompose.query_decompose import query_decompose
            # timestamp_min, timestamp_max, result_df, classified_class = query_decompose(user_query)
            # classified_process = classified_class
            # print(f"query_decompose identified process: {classified_process}")
            print("query_decompose integration pending (another developer's task)")
        except Exception as e:
            print(f"query_decompose failed: {e}, using target_process or legacy mode")

    # 2. target_file ìš°ì„ ìˆœìœ„: ì§ì ‘ ì§€ì • > query_decompose ê²°ê³¼ > target_process(í•˜ìœ„ í˜¸í™˜)
    final_target_file = target_file or classified_process or target_process

    # 3. ì´ìƒ ê°ì§€ ìˆ˜í–‰ (íŒŒì¼ë³„ ëª¨ë¸ ì‚¬ìš©)
    anomalies, drift_results, analysis, vis_json = detect_anomalies_realtime(
        prism_core_db,
        start=start,
        end=end,
        target_file=final_target_file  # ğŸ†• íŒŒì¼ ì§€ì •
    )

    event_record = {
        "task_id": task_id,
        "records": analysis,
        "target_file": final_target_file,  # ğŸ†• íŒŒì¼ ì •ë³´ ì €ì¥
        "validation": {
            "anomalies": anomalies,
            "drift_results": drift_results,
        }
    }
    print('analysis=', analysis)

    Event = Query()
    monitor_db.table('EventDetectHistory').upsert(
        {
            'task_id': task_id,
            'records': analysis,
            'target_file': final_target_file,  # ğŸ†• íŒŒì¼ ì •ë³´ DB ì €ì¥
            'target_process': final_target_file  # ğŸ†• ê³µì • ì •ë³´ (explanationì—ì„œ ì‚¬ìš©)
        },
        Event.task_id == task_id
    )
    print(event_record)

    return {
        'result': {
            'status': 'complete',
            'anomalies': True if len(anomalies) else False,
            'drift_detected': True if len(drift_results) else False,
            'target_file': final_target_file  # ğŸ†• ê²°ê³¼ì— íŒŒì¼ ì •ë³´ í¬í•¨
        }
    }