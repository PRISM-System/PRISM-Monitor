import os

from src.modules.util.util import load_test_scenarios_data

def detect_anomalies_realtime(start: str, end: str,
                               target_file: str = None,  # üÜï ÏàòÏ†ï: CSV ÌååÏùº ÏãùÎ≥ÑÏûê ÏßÄÏ†ï
                               target_process: str = None,  # üìù DEPRECATED: ÌïòÏúÑ Ìò∏ÌôòÏö©
                               model_dir: str = "models",
                               ):  # üÜï CSV ÌååÏùº ÏßÅÏ†ë ÏùΩÍ∏∞ ÏòµÏÖò
    """
    Ïã§ÏãúÍ∞Ñ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Îèô Ïù¥ÏÉÅÌÉêÏßÄ ÏàòÌñâ

    Args:
        prism_core_db: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ (use_csv=TrueÎ©¥ None Í∞ÄÎä•)
        start: ÏãúÏûë ÏãúÍ∞Ñ (ISO format)
        end: Ï¢ÖÎ£å ÏãúÍ∞Ñ (ISO format)
        target_file: üÜï ÌÉêÏßÄÌï† CSV ÌååÏùº (Ïòà: 'semiconductor_cmp_001', 'automotive_welding_001')
                    NoneÏù¥Î©¥ Î†àÍ±∞Ïãú Î™®Îìú
        target_process: üìù DEPRECATED - ÌïòÏúÑ Ìò∏ÌôòÏö©, target_file ÏÇ¨Ïö© Í∂åÏû•
        model_dir: Î™®Îç∏ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ (Í∏∞Î≥∏Í∞í: "models")
        use_csv: Î°úÏª¨ CSV ÌååÏùº ÏßÅÏ†ë ÏùΩÍ∏∞ (API ÎåÄÏã†)

    Returns:
        (anomalies, drift_results, analysis_summary, vis_json)
    """
    print(f"üÜï Ïã§ÏãúÍ∞Ñ Ïù¥ÏÉÅÌÉêÏßÄ ÏãúÏûë (File-Based Model Mode): {start} ~ {end}")

    # ÌïòÏúÑ Ìò∏Ìôò: target_processÍ∞Ä ÏûàÏúºÎ©¥ target_fileÎ°ú Î≥ÄÌôò
    if not target_file and target_process:
        print(f"   ‚ö†Ô∏è  target_processÎäî deprecatedÎê©ÎãàÎã§. target_fileÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.")
        target_file = target_process

    if target_file:
        print(f"   ÎåÄÏÉÅ ÌååÏùº: {target_file}")

    # üÜï Í≥µÏ†ïÎ≥Ñ Î™®Îç∏ ÏßÄÏõê
    if target_file or target_process:
        return _detect_with_process_specific_model(
            prism_core_db, start, end, target_file or target_process, model_dir, use_csv=use_csv
        )
    else:
        # targetÏù¥ ÏßÄÏ†ïÎêòÏßÄ ÏïäÏúºÎ©¥ ÏóêÎü¨
        raise ValueError("target_file ÎòêÎäî target_processÎ•º ÏßÄÏ†ïÌï¥Ïïº Ìï©ÎãàÎã§.")
    
def _detect_with_process_specific_model(start: str, end: str,
                                        target_process: str, model_dir: str):
    """
    Í≥µÏ†ïÎ≥Ñ Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìïú Ïù¥ÏÉÅ ÌÉêÏßÄ (API ÎòêÎäî CSV Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Î°úÎî©)

    Args:
        target_process: Í≥µÏ†ï ÏãùÎ≥ÑÏûê (Ïòà: 'semi_cmp_sensors', 'semiconductor_cmp_001')
        use_csv: TrueÏù¥Î©¥ Î°úÏª¨ CSV ÌååÏùºÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎìú
    """
    from prism_monitor.utils.process_model_manager import ProcessModelManager
    import pandas as pd

    # ÌïòÏúÑ Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌïú Î≥ÑÏπ≠
    target_file = target_process

    print(f"üîç Í≥µÏ†ïÎ≥Ñ Î™®Îç∏Î°ú Ïù¥ÏÉÅ ÌÉêÏßÄ ÏàòÌñâ: {target_process}")
    if use_csv:
        print(f"   üìÅ Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§: Î°úÏª¨ CSV ÌååÏùº (Í∞ïÏ†ú)")
    else:
        print(f"   üåê Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§: API Ïö∞ÏÑ†, Ïã§Ìå® Ïãú CSV Ìè¥Î∞±")

    try:
        # 1. ProcessModelManager Ï¥àÍ∏∞Ìôî
        process_model_manager = ProcessModelManager(base_model_dir=model_dir)

        # 2. Î™®Îç∏ Î°úÎìú
        try:
            model, scaler, metadata = process_model_manager.get_model_for_process(target_process)
            feature_cols = metadata['feature_columns']
            threshold = metadata['threshold']
            print(f"   ‚úì {target_process} Î™®Îç∏ Î°úÎìú ÏôÑÎ£å (features: {len(feature_cols)})")
        except Exception as e:
            print(f"   ‚úó Î™®Îç∏ Î°úÎìú Ïã§Ìå® ({target_process}): {e}")
            return [], [], {'error': f'Model not found: {e}'}, {"error": str(e)}

        # 3. Îç∞Ïù¥ÌÑ∞ Î°úÎî© (API Î®ºÏ†Ä ÏãúÎèÑ, Ïã§Ìå® Ïãú CSVÎ°ú Ìè¥Î∞±)
        data = load_test_scenarios_data(target_process, start, end)


        if len(data) == 0:
            print(f"   ‚ö†Ô∏è  ÏãúÍ∞Ñ Î≤îÏúÑ ÎÇ¥ Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå")
            return [], [], {}, {"anomalies": [], "drift_results": [], "raw_data": {}}

        # 4. Feature Ï∂îÏ∂ú Î∞è Ï†ÑÏ≤òÎ¶¨
        # Î¨∏ÏûêÏó¥ Ïª¨Îüº ÏûêÎèô ÌïÑÌÑ∞ÎßÅ Î∞è ÎàÑÎùΩÎêú feature Ï≤òÎ¶¨
        numeric_feature_cols = []
        for col in feature_cols:
            if col not in data.columns:
                # Ïª¨ÎüºÏù¥ ÏóÜÏúºÎ©¥ 0ÏúºÎ°ú Ï±ÑÏõÄ
                data[col] = 0
                numeric_feature_cols.append(col)
            else:
                # Ïà´ÏûêÌòï Îç∞Ïù¥ÌÑ∞Îßå Ìè¨Ìï®
                if pd.api.types.is_numeric_dtype(data[col]):
                    numeric_feature_cols.append(col)
                else:
                    print(f"   ‚ö†Ô∏è  ÎπÑÏà´Ïûê Ïª¨Îüº Ï†úÏô∏: {col} (ÌÉÄÏûÖ: {data[col].dtype})")

        # Ïà´ÏûêÌòï featureÎßå ÏÇ¨Ïö©
        if len(numeric_feature_cols) != len(feature_cols):
            print(f"   üìù Feature Ï°∞Ï†ï: {len(feature_cols)} ‚Üí {len(numeric_feature_cols)} (Ïà´ÏûêÌòïÎßå)")
            feature_cols = numeric_feature_cols

        X_test = data[feature_cols].values
        X_test = np.nan_to_num(X_test, nan=0.0)
        X_test_scaled = scaler.transform(X_test)

        # 5. Ïù¥ÏÉÅÌÉêÏßÄ
        reconstructed = model.predict(X_test_scaled, verbose=0)
        mse_scores = np.mean(np.square(X_test_scaled - reconstructed), axis=1)

        # 6. Ïù¥ÏÉÅÏπò ÌåêÏ†ï
        anomaly_mask = mse_scores > threshold
        anomaly_indices = np.where(anomaly_mask)[0]

        print(f"   üìä {len(anomaly_indices)}Í∞ú Ïù¥ÏÉÅÏπò ÌÉêÏßÄ (Ï†ÑÏ≤¥ {len(data)}Í∞ú Ï§ë)")

        # 7. Ïù¥ÏÉÅÏπò Î†àÏΩîÎìú ÏÉùÏÑ±
        anomalies = []
        for idx in anomaly_indices:
            anomaly_record = {
                'table_name': target_file,
                'file_identifier': target_file,
                'timestamp': data.iloc[idx].get('timestamp', datetime.now()).isoformat() if hasattr(data.iloc[idx].get('timestamp'), 'isoformat') else str(data.iloc[idx].get('timestamp')),
                'equipment_id': data.iloc[idx].get('sensor_id') or data.iloc[idx].get('equipment_id', 'unknown'),
                'anomaly_type': 'autoencoder_reconstruction_error',
                'anomaly_score': float(mse_scores[idx]),
                'threshold': float(threshold),
                'severity': 'HIGH' if mse_scores[idx] > threshold * 2 else 'MEDIUM',
                'model_used': metadata['model_version'],
                'detection_method': 'file_specific_autoencoder'
            }
            anomalies.append(anomaly_record)

        # 8. Î∂ÑÏÑù ÏöîÏïΩ
        analysis_summary = {
            'total_records': len(data),
            'anomalies_detected': len(anomalies),
            'target_file': target_file,
            'processing_mode': 'process_specific_model',
            'data_source': data_source,  # API ÎòêÎäî CSV
            'processing_time': datetime.now().isoformat(),
            'model_version': metadata['model_version'],
            'threshold': float(threshold)
        }

        # 9. vis_json ÏÉùÏÑ±
        vis_json = {
            "anomalies": convert_to_json_serializable(anomalies),
            "drift_results": [],
            "raw_data": {target_file: dataframe_to_json_serializable(data)},
            "analysis_summary": analysis_summary
        }

        print(f"‚úÖ ÌååÏùºÎ≥Ñ Ïù¥ÏÉÅÌÉêÏßÄ ÏôÑÎ£å: {len(anomalies)}Í∞ú Ïù¥ÏÉÅ ÌÉêÏßÄ")
        return anomalies, [], analysis_summary, vis_json

    except Exception as e:
        print(f"‚ùå ÌååÏùºÎ≥Ñ Ïù¥ÏÉÅÌÉêÏßÄ Ï§ë Ïò§Î•ò: {e}")
        import traceback
        traceback.print_exc()
        return [], [], {'error': str(e)}, {"error": str(e)}
    

def _load_data_from_csv(target_process: str, start: str, end: str):
    """
    Î°úÏª¨ CSV ÌååÏùºÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎìú

    Args:
        target_process: Í≥µÏ†ï ÏãùÎ≥ÑÏûê
        start: ÏãúÏûë ÏãúÍ∞Ñ
        end: Ï¢ÖÎ£å ÏãúÍ∞Ñ

    Returns:
        pandas DataFrame
    """
    import pandas as pd

    # Í≥µÏ†ï Ïù¥Î¶Ñ -> CSV ÌååÏùº Í≤ΩÎ°ú Îß§Ìïë
    process_to_csv = {
        # Semiconductor
        'semiconductor_cmp_001': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_cmp_001.csv',
        'semiconductor_etch_002': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_etch_002.csv',
        'semiconductor_deposition_003': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_deposition_003.csv',
        'semiconductor_full_004': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_full_004.csv',
        # Chemical
        'chemical_reactor_001': 'prism_monitor/test-scenarios/test_data/chemical/chemical_reactor_001.csv',
        'chemical_distillation_002': 'prism_monitor/test-scenarios/test_data/chemical/chemical_distillation_002.csv',
        'chemical_refining_003': 'prism_monitor/test-scenarios/test_data/chemical/chemical_refining_003.csv',
        'chemical_full_004': 'prism_monitor/test-scenarios/test_data/chemical/chemical_full_004.csv',
        # Automotive
        'automotive_welding_001': 'prism_monitor/test-scenarios/test_data/automotive/automotive_welding_001.csv',
        'automotive_painting_002': 'prism_monitor/test-scenarios/test_data/automotive/automotive_painting_002.csv',
        'automotive_press_003': 'prism_monitor/test-scenarios/test_data/automotive/automotive_press_003.csv',
        'automotive_assembly_004': 'prism_monitor/test-scenarios/test_data/automotive/automotive_assembly_004.csv',
        # Battery
        'battery_formation_001': 'prism_monitor/test-scenarios/test_data/battery/battery_formation_001.csv',
        'battery_coating_002': 'prism_monitor/test-scenarios/test_data/battery/battery_coating_002.csv',
        'battery_aging_003': 'prism_monitor/test-scenarios/test_data/battery/battery_aging_003.csv',
        'battery_production_004': 'prism_monitor/test-scenarios/test_data/battery/battery_production_004.csv',
        # Steel
        'steel_rolling_001': 'prism_monitor/test-scenarios/test_data/steel/steel_rolling_001.csv',
        'steel_converter_002': 'prism_monitor/test-scenarios/test_data/steel/steel_converter_002.csv',
        'steel_casting_003': 'prism_monitor/test-scenarios/test_data/steel/steel_casting_003.csv',
        'steel_production_004': 'prism_monitor/test-scenarios/test_data/steel/steel_production_004.csv',
    }

    # CSV ÌååÏùº Í≤ΩÎ°ú Ï∞æÍ∏∞
    csv_path = process_to_csv.get(target_process)
    if not csv_path:
        # ÎåÄÎ¨∏ÏûêÎ°ú ÏãúÎèÑ
        csv_path = process_to_csv.get(target_process.upper())

    if not csv_path or not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSV ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏùå: {target_process}")

    print(f"   üìÇ CSV ÌååÏùº Î°úÎìú: {csv_path}")

    # CSV ÌååÏùº ÏùΩÍ∏∞
    data = pd.read_csv(csv_path)
    print(f"   ‚úì Î°úÎìú ÏôÑÎ£å: {len(data)} Ìñâ")

    # Ïª¨ÎüºÎ™Ö ÏÜåÎ¨∏Ïûê Î≥ÄÌôò
    data.columns = data.columns.str.lower()

    # Timestamp ÌïÑÌÑ∞ÎßÅ
    if 'timestamp' in data.columns:
        data['timestamp'] = pd.to_datetime(data['timestamp'], utc=True)
        start_time = pd.to_datetime(start, utc=True)
        end_time = pd.to_datetime(end, utc=True)
        data = data[(data['timestamp'] >= start_time) & (data['timestamp'] <= end_time)]
        print(f"   ‚úì ÏãúÍ∞Ñ ÌïÑÌÑ∞ÎßÅ ÏôÑÎ£å: {len(data)} Ìñâ (ÏãúÍ∞Ñ Î≤îÏúÑ: {start} ~ {end})")

    return data