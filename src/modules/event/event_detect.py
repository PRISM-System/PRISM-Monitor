import os

from src.modules.util.util import load_test_scenarios_data

def detect_anomalies_realtime(start: str, end: str,
                               target_file: str = None,  # ğŸ†• ìˆ˜ì •: CSV íŒŒì¼ ì‹ë³„ì ì§€ì •
                               target_process: str = None,  # ğŸ“ DEPRECATED: í•˜ìœ„ í˜¸í™˜ìš©
                               model_dir: str = "models",
                               ):  # ğŸ†• CSV íŒŒì¼ ì§ì ‘ ì½ê¸° ì˜µì…˜
    """
    ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ ì´ìƒíƒì§€ ìˆ˜í–‰

    Args:
        prism_core_db: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (use_csv=Trueë©´ None ê°€ëŠ¥)
        start: ì‹œì‘ ì‹œê°„ (ISO format)
        end: ì¢…ë£Œ ì‹œê°„ (ISO format)
        target_file: ğŸ†• íƒì§€í•  CSV íŒŒì¼ (ì˜ˆ: 'semiconductor_cmp_001', 'automotive_welding_001')
                    Noneì´ë©´ ë ˆê±°ì‹œ ëª¨ë“œ
        target_process: ğŸ“ DEPRECATED - í•˜ìœ„ í˜¸í™˜ìš©, target_file ì‚¬ìš© ê¶Œì¥
        model_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: "models")
        use_csv: ë¡œì»¬ CSV íŒŒì¼ ì§ì ‘ ì½ê¸° (API ëŒ€ì‹ )

    Returns:
        (anomalies, drift_results, analysis_summary, vis_json)
    """
    print(f"ğŸ†• ì‹¤ì‹œê°„ ì´ìƒíƒì§€ ì‹œì‘ (File-Based Model Mode): {start} ~ {end}")

    # í•˜ìœ„ í˜¸í™˜: target_processê°€ ìˆìœ¼ë©´ target_fileë¡œ ë³€í™˜
    if not target_file and target_process:
        print(f"   âš ï¸  target_processëŠ” deprecatedë©ë‹ˆë‹¤. target_fileì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        target_file = target_process

    if target_file:
        print(f"   ëŒ€ìƒ íŒŒì¼: {target_file}")

    # ğŸ†• ê³µì •ë³„ ëª¨ë¸ ì§€ì›
    if target_file or target_process:
        return _detect_with_process_specific_model(
            prism_core_db, start, end, target_file or target_process, model_dir, use_csv=use_csv
        )
    else:
        # targetì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬
        raise ValueError("target_file ë˜ëŠ” target_processë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
    
def _detect_with_process_specific_model(start: str, end: str,
                                        target_process: str, model_dir: str):
    """
    ê³µì •ë³„ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ìƒ íƒì§€ (API ë˜ëŠ” CSV ê¸°ë°˜ ë°ì´í„° ë¡œë”©)

    Args:
        target_process: ê³µì • ì‹ë³„ì (ì˜ˆ: 'semi_cmp_sensors', 'semiconductor_cmp_001')
        use_csv: Trueì´ë©´ ë¡œì»¬ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    """
    from prism_monitor.utils.process_model_manager import ProcessModelManager
    import pandas as pd

    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
    target_file = target_process

    print(f"ğŸ” ê³µì •ë³„ ëª¨ë¸ë¡œ ì´ìƒ íƒì§€ ìˆ˜í–‰: {target_process}")
    if use_csv:
        print(f"   ğŸ“ ë°ì´í„° ì†ŒìŠ¤: ë¡œì»¬ CSV íŒŒì¼ (ê°•ì œ)")
    else:
        print(f"   ğŸŒ ë°ì´í„° ì†ŒìŠ¤: API ìš°ì„ , ì‹¤íŒ¨ ì‹œ CSV í´ë°±")

    try:
        # 1. ProcessModelManager ì´ˆê¸°í™”
        process_model_manager = ProcessModelManager(base_model_dir=model_dir)

        # 2. ëª¨ë¸ ë¡œë“œ
        try:
            model, scaler, metadata = process_model_manager.get_model_for_process(target_process)
            feature_cols = metadata['feature_columns']
            threshold = metadata['threshold']
            print(f"   âœ“ {target_process} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (features: {len(feature_cols)})")
        except Exception as e:
            print(f"   âœ— ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({target_process}): {e}")
            return [], [], {'error': f'Model not found: {e}'}, {"error": str(e)}

        # 3. ë°ì´í„° ë¡œë”© (API ë¨¼ì € ì‹œë„, ì‹¤íŒ¨ ì‹œ CSVë¡œ í´ë°±)
        data = load_test_scenarios_data(target_process, start, end)


        if len(data) == 0:
            print(f"   âš ï¸  ì‹œê°„ ë²”ìœ„ ë‚´ ë°ì´í„° ì—†ìŒ")
            return [], [], {}, {"anomalies": [], "drift_results": [], "raw_data": {}}

        # 4. Feature ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        # ë¬¸ìì—´ ì»¬ëŸ¼ ìë™ í•„í„°ë§ ë° ëˆ„ë½ëœ feature ì²˜ë¦¬
        numeric_feature_cols = []
        for col in feature_cols:
            if col not in data.columns:
                # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€
                data[col] = 0
                numeric_feature_cols.append(col)
            else:
                # ìˆ«ìí˜• ë°ì´í„°ë§Œ í¬í•¨
                if pd.api.types.is_numeric_dtype(data[col]):
                    numeric_feature_cols.append(col)
                else:
                    print(f"   âš ï¸  ë¹„ìˆ«ì ì»¬ëŸ¼ ì œì™¸: {col} (íƒ€ì…: {data[col].dtype})")

        # ìˆ«ìí˜• featureë§Œ ì‚¬ìš©
        if len(numeric_feature_cols) != len(feature_cols):
            print(f"   ğŸ“ Feature ì¡°ì •: {len(feature_cols)} â†’ {len(numeric_feature_cols)} (ìˆ«ìí˜•ë§Œ)")
            feature_cols = numeric_feature_cols

        X_test = data[feature_cols].values
        X_test = np.nan_to_num(X_test, nan=0.0)
        X_test_scaled = scaler.transform(X_test)

        # 5. ì´ìƒíƒì§€
        reconstructed = model.predict(X_test_scaled, verbose=0)
        mse_scores = np.mean(np.square(X_test_scaled - reconstructed), axis=1)

        # 6. ì´ìƒì¹˜ íŒì •
        anomaly_mask = mse_scores > threshold
        anomaly_indices = np.where(anomaly_mask)[0]

        print(f"   ğŸ“Š {len(anomaly_indices)}ê°œ ì´ìƒì¹˜ íƒì§€ (ì „ì²´ {len(data)}ê°œ ì¤‘)")

        # 7. ì´ìƒì¹˜ ë ˆì½”ë“œ ìƒì„±
        anomalies = []
        for idx in anomaly_indices:
            anomaly_record = {
                'table_name': target_file,
                'file_identifier': target_file,
                'timestamp': data.iloc[idx].get('timestamp', datetime.now()).isoformat() if hasattr(data.iloc[idx].get('timestamp'), 'isoformat') else str(data.iloc[idx].get('timestamp')),
                'equipment_id': data.iloc[idx].get('sensor_id') or data.iloc[idx].get('equipment_id', 'unknown'),
                'anomaly_type': 'autoencoder_reconstruction_error',
                'anomaly_score': float(mse_scores[idx]),
                'threshold': float(threshold),
                'severity': 'HIGH' if mse_scores[idx] > threshold * 2 else 'MEDIUM',
                'model_used': metadata['model_version'],
                'detection_method': 'file_specific_autoencoder'
            }
            anomalies.append(anomaly_record)

        # 8. ë¶„ì„ ìš”ì•½
        analysis_summary = {
            'total_records': len(data),
            'anomalies_detected': len(anomalies),
            'target_file': target_file,
            'processing_mode': 'process_specific_model',
            'data_source': data_source,  # API ë˜ëŠ” CSV
            'processing_time': datetime.now().isoformat(),
            'model_version': metadata['model_version'],
            'threshold': float(threshold)
        }

        # 9. vis_json ìƒì„±
        vis_json = {
            "anomalies": convert_to_json_serializable(anomalies),
            "drift_results": [],
            "raw_data": {target_file: dataframe_to_json_serializable(data)},
            "analysis_summary": analysis_summary
        }

        print(f"âœ… íŒŒì¼ë³„ ì´ìƒíƒì§€ ì™„ë£Œ: {len(anomalies)}ê°œ ì´ìƒ íƒì§€")
        return anomalies, [], analysis_summary, vis_json

    except Exception as e:
        print(f"âŒ íŒŒì¼ë³„ ì´ìƒíƒì§€ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return [], [], {'error': str(e)}, {"error": str(e)}
    

def _load_data_from_csv(target_process: str, start: str, end: str):
    """
    ë¡œì»¬ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ

    Args:
        target_process: ê³µì • ì‹ë³„ì
        start: ì‹œì‘ ì‹œê°„
        end: ì¢…ë£Œ ì‹œê°„

    Returns:
        pandas DataFrame
    """
    import pandas as pd

    # ê³µì • ì´ë¦„ -> CSV íŒŒì¼ ê²½ë¡œ ë§¤í•‘
    process_to_csv = {
        # Semiconductor
        'semiconductor_cmp_001': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_cmp_001.csv',
        'semiconductor_etch_002': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_etch_002.csv',
        'semiconductor_deposition_003': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_deposition_003.csv',
        'semiconductor_full_004': 'prism_monitor/test-scenarios/test_data/semiconductor/semiconductor_full_004.csv',
        # Chemical
        'chemical_reactor_001': 'prism_monitor/test-scenarios/test_data/chemical/chemical_reactor_001.csv',
        'chemical_distillation_002': 'prism_monitor/test-scenarios/test_data/chemical/chemical_distillation_002.csv',
        'chemical_refining_003': 'prism_monitor/test-scenarios/test_data/chemical/chemical_refining_003.csv',
        'chemical_full_004': 'prism_monitor/test-scenarios/test_data/chemical/chemical_full_004.csv',
        # Automotive
        'automotive_welding_001': 'prism_monitor/test-scenarios/test_data/automotive/automotive_welding_001.csv',
        'automotive_painting_002': 'prism_monitor/test-scenarios/test_data/automotive/automotive_painting_002.csv',
        'automotive_press_003': 'prism_monitor/test-scenarios/test_data/automotive/automotive_press_003.csv',
        'automotive_assembly_004': 'prism_monitor/test-scenarios/test_data/automotive/automotive_assembly_004.csv',
        # Battery
        'battery_formation_001': 'prism_monitor/test-scenarios/test_data/battery/battery_formation_001.csv',
        'battery_coating_002': 'prism_monitor/test-scenarios/test_data/battery/battery_coating_002.csv',
        'battery_aging_003': 'prism_monitor/test-scenarios/test_data/battery/battery_aging_003.csv',
        'battery_production_004': 'prism_monitor/test-scenarios/test_data/battery/battery_production_004.csv',
        # Steel
        'steel_rolling_001': 'prism_monitor/test-scenarios/test_data/steel/steel_rolling_001.csv',
        'steel_converter_002': 'prism_monitor/test-scenarios/test_data/steel/steel_converter_002.csv',
        'steel_casting_003': 'prism_monitor/test-scenarios/test_data/steel/steel_casting_003.csv',
        'steel_production_004': 'prism_monitor/test-scenarios/test_data/steel/steel_production_004.csv',
    }

    # CSV íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    csv_path = process_to_csv.get(target_process)
    if not csv_path:
        # ëŒ€ë¬¸ìë¡œ ì‹œë„
        csv_path = process_to_csv.get(target_process.upper())

    if not csv_path or not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {target_process}")

    print(f"   ğŸ“‚ CSV íŒŒì¼ ë¡œë“œ: {csv_path}")

    # CSV íŒŒì¼ ì½ê¸°
    data = pd.read_csv(csv_path)
    print(f"   âœ“ ë¡œë“œ ì™„ë£Œ: {len(data)} í–‰")

    # ì»¬ëŸ¼ëª… ì†Œë¬¸ì ë³€í™˜
    data.columns = data.columns.str.lower()

    # Timestamp í•„í„°ë§
    if 'timestamp' in data.columns:
        data['timestamp'] = pd.to_datetime(data['timestamp'], utc=True)
        start_time = pd.to_datetime(start, utc=True)
        end_time = pd.to_datetime(end, utc=True)
        data = data[(data['timestamp'] >= start_time) & (data['timestamp'] <= end_time)]
        print(f"   âœ“ ì‹œê°„ í•„í„°ë§ ì™„ë£Œ: {len(data)} í–‰ (ì‹œê°„ ë²”ìœ„: {start} ~ {end})")

    return data