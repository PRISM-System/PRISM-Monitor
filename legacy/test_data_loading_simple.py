#!/usr/bin/env python3
"""
ë°ì´í„° ë¡œë”© ê°„ë‹¨ í…ŒìŠ¤íŠ¸ - torch ì—†ì´
"""

import pandas as pd
import os

def simple_load_test(data_base_path):
    print("=" * 70)
    print("ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ (ê°„ë‹¨ ë²„ì „)")
    print("=" * 70)
    print(f"ë°ì´í„° ê²½ë¡œ: {data_base_path}\n")

    datasets = {}

    # ë””ë ‰í† ë¦¬ íƒìƒ‰
    if os.path.isdir(data_base_path):
        for industry_dir in os.listdir(data_base_path):
            industry_path = os.path.join(data_base_path, industry_dir)

            # íŒŒì¼ì¸ ê²½ìš° (ìµœìƒìœ„ CSV)
            if os.path.isfile(industry_path) and industry_path.endswith('.csv'):
                filename = os.path.basename(industry_path)
                key = filename.replace('.csv', '')
                print(f"ğŸ“„ Loading: {filename}")
                try:
                    df = pd.read_csv(industry_path)
                    datasets[key] = df
                    print(f"   Shape: {df.shape}")
                except Exception as e:
                    print(f"   âŒ Error: {e}")

            # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° (ì¹´í…Œê³ ë¦¬ í´ë”)
            elif os.path.isdir(industry_path):
                print(f"\nğŸ“ Category: {industry_dir}")
                for filename in os.listdir(industry_path):
                    if filename.endswith('.csv'):
                        file_path = os.path.join(industry_path, filename)
                        key = filename.replace('.csv', '')
                        print(f"   Loading: {filename}")
                        try:
                            df = pd.read_csv(file_path)
                            datasets[key] = df
                            print(f"      Shape: {df.shape}")

                            # ID ì»¬ëŸ¼ í™•ì¸
                            id_cols = [col for col in df.columns if col.endswith('_ID')]
                            if id_cols:
                                print(f"      ID ì»¬ëŸ¼: {id_cols[0]}")

                            # ìˆ«ìí˜• ì»¬ëŸ¼
                            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                            print(f"      ìˆ«ìí˜• ì„¼ì„œ: {len(numeric_cols)}ê°œ")

                        except Exception as e:
                            print(f"      âŒ Error: {e}")
                print()

    print("\n" + "=" * 70)
    print("ë¡œë”© ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    print(f"ì´ ë¡œë“œëœ íŒŒì¼ ìˆ˜: {len(datasets)}\n")

    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    categories = {}
    for name in datasets.keys():
        parts = name.split('_')
        if len(parts) > 0:
            category = parts[0]
            categories[category] = categories.get(category, 0) + 1

    print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ìˆ˜:")
    for cat, count in sorted(categories.items()):
        print(f"   {cat}: {count}ê°œ íŒŒì¼")

    print("\n" + "=" * 70)

    # ID ì»¬ëŸ¼ íƒ€ì… í™•ì¸
    print("\nğŸ” ID ì»¬ëŸ¼ ë¶„ì„:")
    id_types = {}
    for name, df in datasets.items():
        id_cols = [col for col in df.columns if col.endswith('_ID')]
        if id_cols:
            id_type = id_cols[0]
            if id_type not in id_types:
                id_types[id_type] = []
            id_types[id_type].append(name)

    for id_type, files in sorted(id_types.items()):
        print(f"\n   {id_type}: {len(files)}ê°œ íŒŒì¼")
        for f in files[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
            print(f"      - {f}")
        if len(files) > 3:
            print(f"      ... ì™¸ {len(files) - 3}ê°œ")

    return datasets

if __name__ == "__main__":
    DATA_PATH = '/home/jonghak/PRISM-Monitor/prism_monitor/test-scenarios/test_data/'
    datasets = simple_load_test(DATA_PATH)

    if datasets:
        print("\nâœ… ë°ì´í„° ë¡œë”© ì„±ê³µ!")
    else:
        print("\nâŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨!")
