# Event Precursor Module

> **ì´ìƒ ì§•í›„ ì‚¬ì „ ì˜ˆì¸¡ ëª¨ë“ˆ**
> LSTM ê¸°ë°˜ ì‹œê³„ì—´ ë¶„ì„ì„ í†µí•œ ì œì¡° ì„¤ë¹„ ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [íŒŒì¼ êµ¬ì¡°](#íŒŒì¼-êµ¬ì¡°)
3. [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
4. [ë°ì´í„° íë¦„](#ë°ì´í„°-íë¦„)
5. [í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤](#í•¨ìˆ˜-ë ˆí¼ëŸ°ìŠ¤)
6. [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
7. [ì…ì¶œë ¥ í˜•ì‹](#ì…ì¶œë ¥-í˜•ì‹)
8. [ì˜ˆì œ](#ì˜ˆì œ)
9. [íŒŒë¼ë¯¸í„° ì„¤ì •](#íŒŒë¼ë¯¸í„°-ì„¤ì •)

---

## ê°œìš”

Event Precursor ëª¨ë“ˆì€ ì œì¡° ê³µì •ì˜ ì„¼ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ **ë¯¸ë˜ì˜ ì´ìƒ ì§•í›„ë¥¼ ì‚¬ì „ì— ì˜ˆì¸¡**í•˜ëŠ” ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•

- **ë‹¤ì¤‘ ì‚°ì—… ì§€ì›**: Automotive, Battery, Chemical, Semiconductor, Steel ë“±
- **LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡**: PyTorchë¥¼ í™œìš©í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸
- **3ê°€ì§€ ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤**:
  1. ë‹¨ì¼ ì¶œë ¥: ì´ìƒ ì§•í›„ ë°œìƒ í™•ë¥  ì˜ˆì¸¡
  2. ë‹¤ì¤‘ ì¶œë ¥: ì„¼ì„œê°’ + ì´ìƒ ì§•í›„ ë™ì‹œ ì˜ˆì¸¡
  3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ì‹¤ì‹œê°„ ë¶„ì„
- **ìë™ ì´ìƒ ë ˆì´ë¸”ë§**: Z-score ê¸°ë°˜ ë¹„ì§€ë„ í•™ìŠµ
- **RUL ì˜ˆì¸¡**: ì”ì—¬ ìœ íš¨ ìˆ˜ëª…(Remaining Useful Life) ì¶”ì •
- **ê²½ê³  ì‹œìŠ¤í…œ**: ìœ„í—˜ë„ë³„ ì•Œë¦¼ ìƒì„± (WARNING/CRITICAL)

### ê¸°ìˆ  ìŠ¤íƒ

```
- Python 3.11
- PyTorch (LSTM ëª¨ë¸)
- Pandas (ë°ì´í„° ì²˜ë¦¬)
- Scikit-learn (ì „ì²˜ë¦¬, ë¶„í• )
- NumPy (ìˆ˜ì¹˜ ì—°ì‚°)
- Matplotlib (ì‹œê°í™”)
```

---

## íŒŒì¼ êµ¬ì¡°

```
event_precursor/
â”œâ”€â”€ _precursor.py      # í•µì‹¬ ë¡œì§ êµ¬í˜„ (ë‚´ë¶€ ëª¨ë“ˆ)
â”œâ”€â”€ precursor.py       # ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤ (ì™¸ë¶€ API)
â””â”€â”€ README.md          # ë¬¸ì„œ (ë³¸ íŒŒì¼)
```

### `_precursor.py` (Core Module)

**ì—­í• **: ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„

**ì£¼ìš” ì»´í¬ë„ŒíŠ¸**:
- ë°ì´í„° ë¡œë”© ë° í†µí•© í•¨ìˆ˜
- ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
- LSTM ëª¨ë¸ ì •ì˜
- í•™ìŠµ ë° ì˜ˆì¸¡ ë¡œì§
- ì‹œê°í™” ìœ í‹¸ë¦¬í‹°

**í•¨ìˆ˜ êµ¬ì„±**:
```python
# ë°ì´í„° ì²˜ë¦¬
- load_and_explore_data()
- load_single_csv()
- integrate_sensor_data()
- create_unified_dataset()
- prepare_features()

# ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
- create_time_series_data()
- create_multi_output_data()

# ëª¨ë¸ ì •ì˜
- create_lstm_model()
- create_multi_output_lstm()

# í•™ìŠµ
- train_lstm_model()
- train_multi_output_model()

# ì˜ˆì¸¡ ë° í‰ê°€
- predict_future_anomalies()
- calculate_remaining_useful_life()
- generate_alerts()

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- real_time_monitoring()
- create_mock_real_time_stream()

# ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
- run_single_output_scenario()
- run_multi_output_scenario()
- run_real_time_monitoring_scenario()

# ì‹œê°í™”
- visualize_predictions()
- plot_rul_distribution()
```

### `precursor.py` (Interface Module)

**ì—­í• **: ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ ì œê³µ

**ì£¼ìš” í•¨ìˆ˜**:

#### 1. `main()`
- **ëª©ì **: ë…ë¦½ ì‹¤í–‰ ëª¨ë“œ
- **ë°ì´í„° ì†ŒìŠ¤**: íŒŒì¼ ì‹œìŠ¤í…œ (CSV íŒŒì¼ë“¤)
- **ê²½ë¡œ**: `../../test-scenarios/test_data/`
- **ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ê°œë°œ, í…ŒìŠ¤íŠ¸, ë°°ì¹˜ ì²˜ë¦¬

```python
def main():
    """
    íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Returns:
        dict: {
            'summary': {
                'predicted_value': float,
                'is_anomaly': str ('0', '1', '2')
            }
        }
    """
```

#### 2. `precursor(datasets)`
- **ëª©ì **: í”„ë¡œê·¸ë˜ë° API
- **ë°ì´í„° ì†ŒìŠ¤**: ì¸ìë¡œ ì „ë‹¬ë°›ì€ datasets (dict)
- **ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**: ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í˜¸ì¶œ, í†µí•© ì‹œìŠ¤í…œ

```python
def precursor(datasets):
    """
    ì™¸ë¶€ì—ì„œ ì „ë‹¬ë°›ì€ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰

    Args:
        datasets (dict): {filename: DataFrame} í˜•íƒœì˜ ë°ì´í„°ì…‹

    Returns:
        dict: {
            'summary': {
                'predicted_value': float,
                'is_anomaly': str
            },
            'error': str (optional)
        }
    """
```

---

## ì£¼ìš” ê¸°ëŠ¥

### 1ï¸âƒ£ ë°ì´í„° ë¡œë”© ë° í†µí•©

**ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬**:
```python
# ë””ë ‰í† ë¦¬ êµ¬ì¡° ì˜ˆì‹œ
test_data/
â”œâ”€â”€ automotive/
â”‚   â”œâ”€â”€ automotive_welding_001.csv
â”‚   â””â”€â”€ automotive_assembly_004.csv
â”œâ”€â”€ battery/
â”‚   â””â”€â”€ battery_formation_001.csv
â””â”€â”€ ...
```

**í†µí•© í”„ë¡œì„¸ìŠ¤**:
1. ëª¨ë“  CSV íŒŒì¼ ë¡œë“œ
2. ì„¼ì„œ ë°ì´í„°ë¥¼ Long Formatìœ¼ë¡œ ë³€í™˜ (melt)
3. TIMESTAMP ê¸°ì¤€ìœ¼ë¡œ Pivotí•˜ì—¬ Wide Format ìƒì„±
4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (forward fill â†’ backward fill â†’ 0)

**ì§€ì› ID ì»¬ëŸ¼**:
- Primary: `SENSOR_ID`, `CHAMBER_ID`, `EQUIPMENT_ID`, `CELL_ID`, `LINE_ID`, `PRODUCTION_LINE`
- Fallback: `*_ID` íŒ¨í„´ (ì˜ˆ: `REACTOR_ID`, `PRESS_ID` ë“±)

### 2ï¸âƒ£ ìë™ ì´ìƒ ë ˆì´ë¸”ë§

**Z-Score ê¸°ë°˜ ë¹„ì§€ë„ í•™ìŠµ**:

```python
# ê° íŠ¹ì„±ë³„ Z-Score ê³„ì‚°
z_scores = abs((feature_data - mean) / std).mean(axis=1)

# ìƒìœ„ 10%ë¥¼ ì´ìƒìœ¼ë¡œ ë¶„ë¥˜
threshold = np.percentile(z_scores, 90)
is_anomaly = z_scores > threshold
```

**íŠ¹ì§•**:
- ë ˆì´ë¸” ë°ì´í„° ë¶ˆí•„ìš”
- Train ë°ì´í„°ì˜ í†µê³„ë§Œ ì‚¬ìš© (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)
- Val/Test ë°ì´í„°ëŠ” Train í†µê³„ë¡œ í‰ê°€

### 3ï¸âƒ£ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±

**Sliding Window ë°©ì‹**:

```
[t-9, t-8, ..., t-1, t] â†’ [t+1 ~ t+5ì— ì´ìƒ ë°œìƒ?]
    â†‘                           â†‘
 sequence_length=10      prediction_horizon=5
```

**ì˜ˆì‹œ**:
```python
# ì…ë ¥: ê³¼ê±° 10 ìŠ¤í…ì˜ ì„¼ì„œê°’
X = [[ì„¼ì„œ1_t-9, ì„¼ì„œ2_t-9, ...],
     [ì„¼ì„œ1_t-8, ì„¼ì„œ2_t-8, ...],
     ...
     [ì„¼ì„œ1_t, ì„¼ì„œ2_t, ...]]     # shape: (10, num_sensors)

# ì¶œë ¥: ë¯¸ë˜ 5 ìŠ¤í… ë‚´ ì´ìƒ ë°œìƒ ì—¬ë¶€
y = 1  # 1: ì´ìƒ ë°œìƒ, 0: ì •ìƒ
```

### 4ï¸âƒ£ LSTM ëª¨ë¸

#### ë‹¨ì¼ ì¶œë ¥ ëª¨ë¸ (LSTMPredictor)

```
Input (batch, seq_len, features)
    â†“
LSTM Layers (hidden_size=64, num_layers=2)
    â†“
Last Time Step Output
    â†“
FC Layer 1 (64 â†’ 32)
    â†“
ReLU + Dropout
    â†“
FC Layer 2 (32 â†’ 1)
    â†“
Sigmoid
    â†“
Anomaly Probability [0-1]
```

**íŠ¹ì§•**:
- Binary Classification (ì´ìƒ ë°œìƒ ì—¬ë¶€)
- Class Imbalance ì²˜ë¦¬ (Weighted BCE Loss)
- Learning Rate Scheduling (ReduceLROnPlateau)

#### ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ (MultiOutputLSTM)

```
Input (batch, seq_len, features)
    â†“
Shared LSTM (hidden_size=128, num_layers=3)
    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                     â†“
   Value Predictor      Anomaly Predictor
   (ì„¼ì„œê°’ ì˜ˆì¸¡)         (ì´ìƒ í™•ë¥  ì˜ˆì¸¡)
         â†“                     â†“
   (batch, 5, features)   (batch, 5)
```

**íŠ¹ì§•**:
- ì„¼ì„œê°’ê³¼ ì´ìƒ ì—¬ë¶€ë¥¼ ë™ì‹œì— ì˜ˆì¸¡
- Multi-task Learning
- Loss = MSE(values) + BCE(anomalies)

### 5ï¸âƒ£ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

**ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬**:

```python
# ìˆœí™˜ ë²„í¼ ë°©ì‹
buffer = [ìµœì‹  sequence_lengthê°œ ë°ì´í„°]

for new_data in stream:
    buffer.append(new_data)
    if len(buffer) >= sequence_length:
        prediction = model(buffer[-sequence_length:])

        if prediction >= 0.7:
            alert("ìœ„í—˜ ê²½ê³ ")
        elif prediction >= 0.3:
            alert("ì£¼ì˜")
```

**ì¶œë ¥ ìƒíƒœ ì½”ë“œ**:
- `'0'`: ì •ìƒ (í™•ë¥  < 0.3)
- `'1'`: ì£¼ì˜ (0.3 â‰¤ í™•ë¥  < 0.7)
- `'2'`: ìœ„í—˜ (í™•ë¥  â‰¥ 0.7)

### 6ï¸âƒ£ RUL ì˜ˆì¸¡ (Remaining Useful Life)

**ì—´í™” ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜**:

```python
for horizon in range(1, max_horizon + 1):
    # ì‹œê°„ì— ë”°ë¥¸ ê°€ìƒ ì—´í™” ì ìš©
    degradation_factor = 1 + (horizon * 0.015)
    adjusted_prob = min(prob * degradation_factor, 1.0)

    if adjusted_prob >= failure_threshold:
        return horizon  # RUL
```

**í™œìš©**:
- ì˜ˆë°© ì •ë¹„ ì¼ì • ê³„íš
- ë¶€í’ˆ êµì²´ ì‹œê¸° ì˜ˆì¸¡
- ìƒì‚° ì¤‘ë‹¨ ìµœì†Œí™”

---

## ë°ì´í„° íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CSV íŒŒì¼ë“¤          â”‚
â”‚  (multiple files)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ load_and_explore_   â”‚
â”‚ data()              â”‚  â† 1. ë°ì´í„° ë¡œë”©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  datasets  â”‚  (dict)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ integrate_sensor_   â”‚
â”‚ data()              â”‚  â† 2. Long Format ë³€í™˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ create_unified_     â”‚
â”‚ dataset()           â”‚  â† 3. Pivot â†’ Wide Format
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ unified_df â”‚  (pivot table)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ train_test_split    â”‚  â† 4. ë°ì´í„° ë¶„í• 
â”‚ (ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€)   â”‚     (Train:Val:Test = 81:9:10)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ train_df â”‚ val_df â”‚ test_df
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”¬â”€â”€â”€â”˜
         â†“          â†“       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prepare_features()  â”‚  â† 5. ì „ì²˜ë¦¬
â”‚  - Z-score ì´ìƒ íƒì§€â”‚
â”‚  - StandardScaler   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ create_time_series_ â”‚  â† 6. ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
â”‚ data()              â”‚     (Sliding Window)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ X, y   â”‚  (sequences, labels)
      â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ create_lstm_model() â”‚  â† 7. ëª¨ë¸ ìƒì„±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ train_lstm_model()  â”‚  â† 8. í•™ìŠµ
â”‚  - BCELoss          â”‚
â”‚  - Adam Optimizer   â”‚
â”‚  - LR Scheduling    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ trained_modelâ”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ predict_future_anomalies()  â”‚  â† 9. ì˜ˆì¸¡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ anomaly_probsâ”‚  (probabilities)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ generate_alerts()   â”‚  â† 10. ê²½ê³  ìƒì„±
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ alerts â”‚  (list of alerts)
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤

### ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜

#### `load_and_explore_data(data_base_path)`

**ëª©ì **: ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  CSV íŒŒì¼ ë¡œë“œ

**ì¸ì**:
- `data_base_path` (str): ë°ì´í„° í´ë” ê²½ë¡œ

**ë°˜í™˜**:
- `dict`: `{filename: DataFrame}` í˜•íƒœ

**ë™ì‘**:
```python
# íŒŒì¼ ì§ì ‘ ë¡œë“œ
if file.endswith('.csv'):
    datasets[filename] = pd.read_csv(file)

# í•˜ìœ„ ë””ë ‰í† ë¦¬ íƒìƒ‰
for subdir in os.listdir(data_base_path):
    for file in os.listdir(subdir):
        if file.endswith('.csv'):
            datasets[filename] = pd.read_csv(file)
```

**ì˜ˆì‹œ**:
```python
datasets = load_and_explore_data('/path/to/test_data/')
# Returns:
# {
#   'automotive_welding_001': DataFrame(...),
#   'battery_formation_001': DataFrame(...),
#   ...
# }
```

---

#### `integrate_sensor_data(datasets)`

**ëª©ì **: ë‹¤ì¤‘ ë°ì´í„°ì…‹ì„ Long Formatìœ¼ë¡œ í†µí•©

**ì¸ì**:
- `datasets` (dict): `{filename: DataFrame}` í˜•íƒœ

**ë°˜í™˜**:
- `DataFrame`: Long format í†µí•© ë°ì´í„°
  - Columns: `['TIMESTAMP', equipment_col, 'sensor_table', 'sensor_type', 'sensor_value']`

**ì²˜ë¦¬ ê³¼ì •**:
```python
# Wide Format (ì›ë³¸)
TIMESTAMP | SENSOR_ID | TEMP | PRESSURE | VOLTAGE
2025-01   | S001      | 25.0 | 1.2      | 220

# Long Format (ë³€í™˜ í›„)
TIMESTAMP | SENSOR_ID | sensor_table | sensor_type | sensor_value
2025-01   | S001      | file1        | TEMP        | 25.0
2025-01   | S001      | file1        | PRESSURE    | 1.2
2025-01   | S001      | file1        | VOLTAGE     | 220
```

---

#### `create_unified_dataset(datasets)`

**ëª©ì **: Long Format ë°ì´í„°ë¥¼ Pivotí•˜ì—¬ Wide Formatìœ¼ë¡œ ë³€í™˜

**ì¸ì**:
- `datasets` (dict): `{filename: DataFrame}`

**ë°˜í™˜**:
- `DataFrame`: Wide format í†µí•© ë°ì´í„°
  - Index: `TIMESTAMP`
  - Columns: `sensor_TEMP`, `sensor_PRESSURE`, ... + `equipment_id` (optional)

**ì²˜ë¦¬ ê³¼ì •**:
```python
# 1. integrate_sensor_data() í˜¸ì¶œ
# 2. pivot_table ìƒì„±
sensor_pivot = integrated.pivot_table(
    index='TIMESTAMP',
    columns='sensor_type',
    values='sensor_value',
    aggfunc='mean'
)

# 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
sensor_pivot = sensor_pivot.ffill().bfill().fillna(0)

# 4. equipment_id ë³‘í•© (ìˆëŠ” ê²½ìš°)
```

---

#### `prepare_features(df, train_stats=None)`

**ëª©ì **: íŠ¹ì„± ì „ì²˜ë¦¬ ë° ì´ìƒ ë ˆì´ë¸”ë§

**ì¸ì**:
- `df` (DataFrame): ì…ë ¥ ë°ì´í„°
- `train_stats` (dict, optional): Train ë°ì´í„°ì˜ í†µê³„ëŸ‰
  - `None`: ìƒˆë¡œ ê³„ì‚° (Train ë°ì´í„°)
  - `dict`: ê¸°ì¡´ í†µê³„ ì‚¬ìš© (Val/Test ë°ì´í„°)

**ë°˜í™˜**:
- `df_processed` (DataFrame): ì „ì²˜ë¦¬ëœ ë°ì´í„° + `is_anomaly` ì»¬ëŸ¼
- `feature_cols` (list): íŠ¹ì„± ì»¬ëŸ¼ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
- `scaler` (StandardScaler): í•™ìŠµëœ ìŠ¤ì¼€ì¼ëŸ¬
- `train_stats` (dict): í†µê³„ëŸ‰ `{'mean': ..., 'std': ...}`

**ì²˜ë¦¬ ê³¼ì •**:
```python
# 1. ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì¶”ì¶œ
numeric_cols = df.select_dtypes(include=[np.number]).columns

# 2. ì´ìƒ ë ˆì´ë¸”ë§ (Z-score)
z_scores = abs((data - mean) / std).mean(axis=1)
threshold = np.percentile(z_scores, 90)
df['is_anomaly'] = z_scores > threshold

# 3. ì •ê·œí™” (StandardScaler)
df[feature_cols] = scaler.fit_transform(df[feature_cols])
```

**ì£¼ì˜ì‚¬í•­**:
- Train ë°ì´í„°ëŠ” `train_stats=None`ìœ¼ë¡œ í˜¸ì¶œ
- Val/Test ë°ì´í„°ëŠ” Trainì˜ `train_stats`ë¥¼ ì „ë‹¬í•˜ì—¬ **ë°ì´í„° ëˆ„ì¶œ ë°©ì§€**

---

### ì‹œê³„ì—´ ë°ì´í„° ìƒì„±

#### `create_time_series_data(data, feature_cols, sequence_length=10, prediction_horizon=5)`

**ëª©ì **: Sliding Window ë°©ì‹ìœ¼ë¡œ ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±

**ì¸ì**:
- `data` (DataFrame): ì „ì²˜ë¦¬ëœ ë°ì´í„° (with `is_anomaly`)
- `feature_cols` (list): íŠ¹ì„± ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
- `sequence_length` (int): ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (ê¸°ë³¸: 10)
- `prediction_horizon` (int): ì˜ˆì¸¡ êµ¬ê°„ (ê¸°ë³¸: 5)

**ë°˜í™˜**:
- `X` (np.ndarray): ì…ë ¥ ì‹œí€€ìŠ¤, shape: `(num_samples, sequence_length, num_features)`
- `y` (np.ndarray): íƒ€ê²Ÿ ë ˆì´ë¸”, shape: `(num_samples,)`
  - `1`: ë¯¸ë˜ êµ¬ê°„ì— ì´ìƒ ë°œìƒ
  - `0`: ì •ìƒ

**ë™ì‘**:
```python
for i in range(sequence_length, len(data) - prediction_horizon):
    # ì…ë ¥: ê³¼ê±° ë°ì´í„°
    X.append(data[i-sequence_length : i])

    # ì¶œë ¥: ë¯¸ë˜ êµ¬ê°„ ë‚´ ì´ìƒ ë°œìƒ ì—¬ë¶€
    future_window = data['is_anomaly'][i+1 : i+1+prediction_horizon]
    y.append(1 if future_window.any() else 0)
```

**ì˜ˆì‹œ**:
```python
X, y = create_time_series_data(
    data=train_df,
    feature_cols=['sensor_TEMP', 'sensor_PRESSURE'],
    sequence_length=10,
    prediction_horizon=5
)
# X.shape: (4900, 10, 2)
# y.shape: (4900,)
```

---

#### `create_multi_output_data(data, feature_cols, sequence_length=10, prediction_steps=5)`

**ëª©ì **: ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ìš© ë°ì´í„° ìƒì„± (ì„¼ì„œê°’ + ì´ìƒ ì—¬ë¶€)

**ë°˜í™˜**:
- `X`: ì…ë ¥ ì‹œí€€ìŠ¤
- `y_values`: ë¯¸ë˜ ì„¼ì„œê°’ (shape: `(N, prediction_steps, num_features)`)
- `y_anomalies`: ë¯¸ë˜ ì´ìƒ ì—¬ë¶€ (shape: `(N, prediction_steps)`)

---

### ëª¨ë¸ ì •ì˜

#### `create_lstm_model(input_size, hidden_size=64, num_layers=2, dropout=0.2)`

**ëª©ì **: ë‹¨ì¼ ì¶œë ¥ LSTM ëª¨ë¸ ìƒì„±

**ì¸ì**:
- `input_size` (int): ì…ë ¥ íŠ¹ì„± ê°œìˆ˜
- `hidden_size` (int): LSTM hidden state í¬ê¸°
- `num_layers` (int): LSTM ë ˆì´ì–´ ìˆ˜
- `dropout` (float): Dropout ë¹„ìœ¨

**ë°˜í™˜**:
- `LSTMPredictor`: PyTorch ëª¨ë¸

**ëª¨ë¸ êµ¬ì¡°**:
```python
class LSTMPredictor(nn.Module):
    - LSTM(input_size â†’ hidden_size, num_layers)
    - Linear(hidden_size â†’ 32)
    - ReLU + Dropout
    - Linear(32 â†’ 1)
    - Sigmoid
```

---

#### `create_multi_output_lstm(input_size, hidden_size=128, num_layers=3, prediction_steps=5, num_features=None)`

**ëª©ì **: ë‹¤ì¤‘ ì¶œë ¥ LSTM ëª¨ë¸ ìƒì„±

**ë°˜í™˜**:
- `MultiOutputLSTM`: PyTorch ëª¨ë¸

**ëª¨ë¸ êµ¬ì¡°**:
```python
class MultiOutputLSTM(nn.Module):
    - Shared LSTM
    - value_predictor: ì„¼ì„œê°’ ì˜ˆì¸¡ í—¤ë“œ
    - anomaly_predictor: ì´ìƒ í™•ë¥  ì˜ˆì¸¡ í—¤ë“œ
```

---

### í•™ìŠµ í•¨ìˆ˜

#### `train_lstm_model(model, X_train, y_train, X_val, y_val, epochs=50, batch_size=32, learning_rate=0.001)`

**ëª©ì **: LSTM ëª¨ë¸ í•™ìŠµ

**ì¸ì**:
- `model`: PyTorch ëª¨ë¸
- `X_train`, `y_train`: í•™ìŠµ ë°ì´í„°
- `X_val`, `y_val`: ê²€ì¦ ë°ì´í„°
- `epochs` (int): ì—í¬í¬ ìˆ˜
- `batch_size` (int): ë°°ì¹˜ í¬ê¸°
- `learning_rate` (float): í•™ìŠµë¥ 

**ë°˜í™˜**:
- `trained_model`: í•™ìŠµëœ ëª¨ë¸
- `train_losses` (list): ì—í¬í¬ë³„ í•™ìŠµ ì†ì‹¤
- `val_losses` (list): ì—í¬í¬ë³„ ê²€ì¦ ì†ì‹¤

**ì£¼ìš” íŠ¹ì§•**:
```python
# Class Imbalance ì²˜ë¦¬
pos_weight = num_neg / num_pos
loss = F.binary_cross_entropy(pred, target, weight=batch_weights)

# Learning Rate Scheduling
scheduler = ReduceLROnPlateau(optimizer, patience=5, factor=0.5)
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬: pos_weight=9.23 (ì–‘ì„±: 500, ìŒì„±: 4500)
ëª¨ë¸ í•™ìŠµ ì‹œì‘...
Epoch [10/50] - Train Loss: 0.3421, Val Loss: 0.3298
Epoch [20/50] - Train Loss: 0.2156, Val Loss: 0.2089
...
```

---

### ì˜ˆì¸¡ í•¨ìˆ˜

#### `predict_future_anomalies(model, X_test, threshold=0.5)`

**ëª©ì **: ì´ìƒ í™•ë¥  ì˜ˆì¸¡

**ì¸ì**:
- `model`: í•™ìŠµëœ PyTorch ëª¨ë¸
- `X_test`: í…ŒìŠ¤íŠ¸ ë°ì´í„°
- `threshold` (float): ì´ìƒ íŒì • ì„ê³„ê°’

**ë°˜í™˜**:
- `anomaly_probs` (np.ndarray): ì´ìƒ í™•ë¥  [0-1]
- `anomaly_labels` (np.ndarray): ì´ì§„ ë ˆì´ë¸” {0, 1}

**ì˜ˆì‹œ**:
```python
probs, labels = predict_future_anomalies(model, X_test, threshold=0.5)
# probs: [0.23, 0.78, 0.45, ...]
# labels: [0, 1, 0, ...]
```

---

#### `generate_alerts(anomaly_probs, lot_numbers=None, alert_threshold=0.7, warning_threshold=0.5)`

**ëª©ì **: ê²½ê³  ë©”ì‹œì§€ ìƒì„±

**ì¸ì**:
- `anomaly_probs` (array): ì´ìƒ í™•ë¥ 
- `lot_numbers` (list, optional): ìƒ˜í”Œ ì‹ë³„ì (TIMESTAMP ë˜ëŠ” equipment_id)
- `alert_threshold` (float): ìœ„í—˜ ê²½ê³  ì„ê³„ê°’ (ê¸°ë³¸: 0.7)
- `warning_threshold` (float): ì£¼ì˜ ê²½ê³  ì„ê³„ê°’ (ê¸°ë³¸: 0.5)

**ë°˜í™˜**:
- `alerts` (list of dict): ê²½ê³  ëª©ë¡

**ê²½ê³  ë ˆë²¨**:
- `CRITICAL`: í™•ë¥  â‰¥ 0.7
- `WARNING`: 0.5 â‰¤ í™•ë¥  < 0.7
- (ë¬´ì‹œ): í™•ë¥  < 0.5

**ì¶œë ¥ í˜•ì‹**:
```python
[
    {
        'sample_id': 'sample_0042',
        'alert_level': 'CRITICAL',
        'probability': 0.85,
        'message': 'ìœ„í—˜! : Sample sample_0042 - ì´ìƒ ë°œìƒ í™•ë¥  85.0%',
        'action': 'ì¦‰ì‹œ ì ê²€ í•„ìš”',
        'timestamp': datetime.now()
    },
    ...
]
```

---

#### `calculate_remaining_useful_life(model, current_data_seq, max_horizon=100, failure_threshold=0.8)`

**ëª©ì **: ì”ì—¬ ìœ íš¨ ìˆ˜ëª…(RUL) ì˜ˆì¸¡

**ì¸ì**:
- `model`: í•™ìŠµëœ ëª¨ë¸
- `current_data_seq`: í˜„ì¬ ì‹œí€€ìŠ¤ ë°ì´í„° (shape: `(sequence_length, num_features)`)
- `max_horizon` (int): ìµœëŒ€ ì˜ˆì¸¡ ë²”ìœ„
- `failure_threshold` (float): ê³ ì¥ íŒì • í™•ë¥  (ê¸°ë³¸: 0.8)

**ë°˜í™˜**:
- `rul` (int): ì˜ˆìƒ ì”ì—¬ ìˆ˜ëª… (ìŠ¤í… ìˆ˜)

**ë™ì‘**:
```python
for horizon in range(1, max_horizon + 1):
    prob = model(current_data)
    degradation_factor = 1 + (horizon * 0.015)  # ì‹œê°„ì— ë”°ë¥¸ ì—´í™”
    adjusted_prob = prob * degradation_factor

    if adjusted_prob >= failure_threshold:
        return horizon  # RUL
```

---

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

#### `real_time_monitoring(model, scaler, feature_cols, new_data_stream, sequence_length=10, update_interval=1)`

**ëª©ì **: ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ëª¨ë‹ˆí„°ë§

**ì¸ì**:
- `model`: í•™ìŠµëœ ëª¨ë¸
- `scaler`: StandardScaler ê°ì²´
- `feature_cols`: íŠ¹ì„± ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
- `new_data_stream`: Iterator (yields `(timestamp, data_row)`)
- `sequence_length`: ì‹œí€€ìŠ¤ ê¸¸ì´
- `update_interval`: ì—…ë°ì´íŠ¸ ì£¼ê¸° (ì´ˆ)

**ë°˜í™˜**:
- `max_status` (str): ì „ì²´ ëª¨ë‹ˆí„°ë§ ê¸°ê°„ ì¤‘ ìµœëŒ€ ìœ„í—˜ ë ˆë²¨
  - `'0'`: ì •ìƒ
  - `'1'`: ì£¼ì˜
  - `'2'`: ìœ„í—˜

**ë™ì‘**:
```python
buffer = []  # ìˆœí™˜ ë²„í¼

for timestamp, new_data in stream:
    buffer.append(preprocess(new_data))

    if len(buffer) >= sequence_length:
        prob = model(buffer[-sequence_length:])

        if prob >= 0.7:
            print(f"[{timestamp}] ìœ„í—˜ ê²½ê³ : ì´ìƒ í™•ë¥  {prob:.1%}")
            max_status = '2'
        elif prob >= 0.3:
            print(f"[{timestamp}] ì£¼ì˜: ì´ìƒ ì§•í›„ ê°ì§€")
            if max_status < '1':
                max_status = '1'
```

---

### ì‹œë‚˜ë¦¬ì˜¤ í•¨ìˆ˜

#### `run_single_output_scenario(train_df, val_df, test_df, feature_cols, scaler)`

**ëª©ì **: ì‹œë‚˜ë¦¬ì˜¤ 1 - ë‹¨ì¼ ì¶œë ¥ ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ì „ì²´ íŒŒì´í”„ë¼ì¸

**ì²˜ë¦¬ ê³¼ì •**:
```
1. ì‹œê³„ì—´ ë°ì´í„° ìƒì„± (sequence_length=2, prediction_horizon=1)
2. LSTM ëª¨ë¸ ìƒì„±
3. ëª¨ë¸ í•™ìŠµ (10 epochs)
4. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
5. ê²½ê³  ìƒì„±
6. RUL ì˜ˆì¸¡ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
```

**ë°˜í™˜**:
- `trained_model`: í•™ìŠµëœ ëª¨ë¸
- `scaler`: ìŠ¤ì¼€ì¼ëŸ¬

---

#### `run_multi_output_scenario(train_df, val_df, test_df, feature_cols)`

**ëª©ì **: ì‹œë‚˜ë¦¬ì˜¤ 2 - ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ (ì„¼ì„œê°’ + ì´ìƒ ì§•í›„)

**ë°˜í™˜**:
- `pred_value` (np.ndarray): ì˜ˆì¸¡ëœ ë¯¸ë˜ ì´ìƒ í™•ë¥  (ì²« ë²ˆì§¸ ìƒ˜í”Œ)

---

#### `run_real_time_monitoring_scenario(trained_model, scaler, feature_cols, test_df)`

**ëª©ì **: ì‹œë‚˜ë¦¬ì˜¤ 3 - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜

**ë°˜í™˜**:
- `anomaly_status` (str): ìµœì¢… ìƒíƒœ ì½”ë“œ (`'0'`, `'1'`, `'2'`)

---

## ì‚¬ìš© ë°©ë²•

### ë°©ë²• 1: ë…ë¦½ ì‹¤í–‰ (main í•¨ìˆ˜)

**ì‹œë‚˜ë¦¬ì˜¤**: CSV íŒŒì¼ë“¤ë¡œë¶€í„° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
cd prism_monitor/modules/event_precursor
python precursor.py
```

**ì½”ë“œ**:
```python
# precursor.py
if __name__ == "__main__":
    main()
```

**ë°ì´í„° ê²½ë¡œ ì„¤ì •**:
```python
# precursor.pyì˜ main() í•¨ìˆ˜ ë‚´ë¶€
DATA_BASE_PATH = '../../test-scenarios/test_data/'
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
============================================================
ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ëª¨ë“ˆ ì‹œì‘
============================================================

[1/6] ë°ì´í„° ë¡œë”©...
Loading: automotive/automotive_welding_001.csv
  - Shape: (5000, 11)
...
ì´ ë¡œë“œëœ íŒŒì¼ ìˆ˜: 20

[2/6] ë°ì´í„° í†µí•©...
ì„¼ì„œ ë°ì´í„° í†µí•©...
  - automotive_welding_001: Sensor count: 9, Record count: 5000
...
í†µí•© ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: (100000, 181)

[3/6] ë°ì´í„° ë¶„í•  (Train/Val/Test)...

[4/6] íŠ¹ì„± ì „ì²˜ë¦¬ ë° ì´ìƒ ë ˆì´ë¸”ë§...
  - Train ë°ì´í„°ë¡œ í†µê³„ ê³„ì‚°
ì „ì²˜ë¦¬ ì™„ë£Œ: 180ê°œ íŠ¹ì„±
ì´ìƒ ë°ì´í„° ë¹„ìœ¨: 10.00%
  - Val/Test ë°ì´í„°ëŠ” Train í†µê³„ ì‚¬ìš© (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)

ë°ì´í„° ë¶„í•  ì™„ë£Œ:
  - í•™ìŠµ ë°ì´í„°: (72900, 182)
  - ê²€ì¦ ë°ì´í„°: (8100, 182)
  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: (10000, 182)
  - íŠ¹ì„± ê°œìˆ˜: 180

[5/6] ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡...

>> ì‹œë‚˜ë¦¬ì˜¤ 1: ë‹¨ì¼ ì¶œë ¥ ì´ìƒ ì§•í›„ ì˜ˆì¸¡
1. ë‹¨ì¼ ì¶œë ¥ ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ëª¨ë¸
ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì™„ë£Œ: X shape=(72898, 2, 180), y shape=(72898,)
í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬: pos_weight=9.12
ëª¨ë¸ í•™ìŠµ ì‹œì‘...
Epoch [10/10] - Train Loss: 0.2345, Val Loss: 0.2198

í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ë° ê²½ê³  ìƒì„±
ì´ 15ê°œì˜ ê²½ê³ ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
  - ìœ„í—˜! : Sample 2025-05-01T12:34:00Z - ì´ìƒ ë°œìƒ í™•ë¥  78.5%
  - ê²½ê³ : Sample 2025-05-01T14:22:00Z - ì´ìƒ ì§•í›„ ê°ì§€ (í™•ë¥  62.3%)
  ...

RUL ì˜ˆì¸¡ ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²« ë²ˆì§¸ ìƒ˜í”Œ)
ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì˜ ì˜ˆì¸¡ RUL: 42 ìŠ¤í…

>> ì‹œë‚˜ë¦¬ì˜¤ 2: ë‹¤ì¤‘ ì¶œë ¥ ì„¼ì„œê°’ ë° ì´ìƒ ì§•í›„ ë™ì‹œ ì˜ˆì¸¡
...

[6/6] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§...
ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘...
[2025-10-24T10:00:00] ì•ˆì „: ì´ìƒ ì§•í›„ ë°œìƒ ê°€ëŠ¥ì„± ë‚®ìŒ (í™•ë¥  12.3%)
[2025-10-24T10:00:10] ì£¼ì˜: ì´ìƒ ì§•í›„ ê°ì§€ (í™•ë¥  45.6%)
...

ëª¨ë‹ˆí„°ë§ ì™„ë£Œ: ìµœëŒ€ ì´ìƒ í™•ë¥  78.5%, ìƒíƒœ: 2

============================================================
ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ì™„ë£Œ
============================================================
```

---

### ë°©ë²• 2: í”„ë¡œê·¸ë˜ë° API (precursor í•¨ìˆ˜)

**ì‹œë‚˜ë¦¬ì˜¤**: ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©

```python
from prism_monitor.modules.event_precursor.precursor import precursor

# ë°ì´í„° ì¤€ë¹„ (dict of DataFrames)
datasets = {
    'welding_data': pd.read_csv('welding.csv'),
    'battery_data': pd.read_csv('battery.csv'),
    ...
}

# Precursor ì‹¤í–‰
result = precursor(datasets)

# ê²°ê³¼ í™•ì¸
print(result)
# {
#     'summary': {
#         'predicted_value': 0.456,
#         'is_anomaly': '1'
#     }
# }
```

---

### ë°©ë²• 3: ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸

**ì‹œë‚˜ë¦¬ì˜¤**: ì„¸ë¶€ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°

```python
from prism_monitor.modules.event_precursor._precursor import (
    load_and_explore_data,
    create_unified_dataset,
    prepare_features,
    create_time_series_data,
    create_lstm_model,
    train_lstm_model,
    predict_future_anomalies,
    generate_alerts
)
from sklearn.model_selection import train_test_split

# 1. ë°ì´í„° ë¡œë“œ
datasets = load_and_explore_data('/path/to/data')

# 2. í†µí•©
unified_df = create_unified_dataset(datasets)

# 3. ë¶„í• 
train_val_df, test_df = train_test_split(unified_df, test_size=0.1, shuffle=False)
train_df, val_df = train_test_split(train_val_df, test_size=0.1, shuffle=False)

# 4. ì „ì²˜ë¦¬
train_df, feature_cols, scaler, train_stats = prepare_features(train_df)
val_df, _, _, _ = prepare_features(val_df, train_stats=train_stats)
test_df, _, _, _ = prepare_features(test_df, train_stats=train_stats)

# 5. ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
X_train, y_train = create_time_series_data(train_df, feature_cols,
                                           sequence_length=10,
                                           prediction_horizon=5)
X_val, y_val = create_time_series_data(val_df, feature_cols, 10, 5)
X_test, y_test = create_time_series_data(test_df, feature_cols, 10, 5)

# 6. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = create_lstm_model(input_size=X_train.shape[2],
                         hidden_size=128,
                         num_layers=3)

trained_model, train_losses, val_losses = train_lstm_model(
    model, X_train, y_train, X_val, y_val,
    epochs=100, batch_size=64, learning_rate=0.001
)

# 7. ì˜ˆì¸¡
probs, labels = predict_future_anomalies(trained_model, X_test, threshold=0.5)

# 8. ê²½ê³  ìƒì„±
timestamps = test_df['TIMESTAMP'].iloc[10:len(probs)+10].tolist()
alerts = generate_alerts(probs, lot_numbers=timestamps,
                        alert_threshold=0.8,
                        warning_threshold=0.6)

# 9. ê²°ê³¼ ì¶œë ¥
for alert in alerts:
    print(f"[{alert['alert_level']}] {alert['message']}")
```

---

## ì…ì¶œë ¥ í˜•ì‹

### ì…ë ¥ ë°ì´í„° í˜•ì‹

#### CSV íŒŒì¼ ìš”êµ¬ì‚¬í•­

**í•„ìˆ˜ ì»¬ëŸ¼**:
- `TIMESTAMP`: ISO 8601 í˜•ì‹ (ì˜ˆ: `2025-05-01T00:00:00Z`)

**ì„ íƒ ì»¬ëŸ¼** (í•˜ë‚˜ ì´ìƒ ê¶Œì¥):
- Equipment ID: `SENSOR_ID`, `CHAMBER_ID`, `LINE_ID`, `PRODUCTION_LINE` ë“±

**ì„¼ì„œ ë°ì´í„°**:
- ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ (float/int)
- ì˜ˆ: `TEMPERATURE`, `PRESSURE`, `VOLTAGE`, `CURRENT` ë“±

**ì˜ˆì‹œ CSV**:
```csv
TIMESTAMP,SENSOR_ID,TEMPERATURE,PRESSURE,VOLTAGE,CURRENT
2025-05-01T00:00:00Z,SENSOR_001,25.3,1.21,220.5,15.2
2025-05-01T00:00:10Z,SENSOR_001,25.5,1.22,220.7,15.3
2025-05-01T00:00:20Z,SENSOR_001,25.8,1.20,221.0,15.1
...
```

#### datasets ë”•ì…”ë„ˆë¦¬ í˜•ì‹

```python
datasets = {
    'automotive_welding_001': pd.DataFrame({
        'TIMESTAMP': [...],
        'LINE_ID': [...],
        'WELD_CURRENT': [...],
        'WELD_VOLTAGE': [...],
        ...
    }),
    'battery_formation_001': pd.DataFrame({
        'TIMESTAMP': [...],
        'CELL_ID': [...],
        'VOLTAGE': [...],
        'CURRENT': [...],
        ...
    }),
    ...
}
```

---

### ì¶œë ¥ ë°ì´í„° í˜•ì‹

#### `main()` í•¨ìˆ˜ ì¶œë ¥

```python
{
    'summary': {
        'predicted_value': np.ndarray,  # ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’
        'is_anomaly': str               # '0', '1', '2'
    }
}
```

#### `precursor(datasets)` í•¨ìˆ˜ ì¶œë ¥

**ì •ìƒ ì‹¤í–‰**:
```python
{
    'summary': {
        'predicted_value': 0.456,  # float
        'is_anomaly': '1'          # str: '0' (ì •ìƒ) | '1' (ì£¼ì˜) | '2' (ìœ„í—˜)
    }
}
```

**ì—ëŸ¬ ë°œìƒ**:
```python
{
    'summary': {
        'predicted_value': 0.0,
        'is_anomaly': '0'
    },
    'error': 'ë°ì´í„°ì…‹ í†µí•© ì‹¤íŒ¨'
}
```

#### ê²½ê³  ë¦¬ìŠ¤íŠ¸ í˜•ì‹

```python
[
    {
        'sample_id': 'sample_0042',
        'alert_level': 'CRITICAL',
        'probability': 0.85,
        'message': 'ìœ„í—˜! : Sample sample_0042 - ì´ìƒ ë°œìƒ í™•ë¥  85.0%',
        'action': 'ì¦‰ì‹œ ì ê²€ í•„ìš”',
        'timestamp': datetime(2025, 10, 24, 14, 30, 0)
    },
    {
        'sample_id': 'sample_0067',
        'alert_level': 'WARNING',
        'probability': 0.62,
        'message': 'ê²½ê³ : Sample sample_0067 - ì´ìƒ ì§•í›„ ê°ì§€ (í™•ë¥  62.0%)',
        'action': 'ì˜ˆë°© ì ê²€ ê¶Œì¥',
        'timestamp': datetime(2025, 10, 24, 14, 31, 0)
    }
]
```

---

## ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš© (main í•¨ìˆ˜)

```python
# precursor.pyë¥¼ ì§ì ‘ ì‹¤í–‰
python precursor.py
```

---

### ì˜ˆì œ 2: ì™¸ë¶€ ëª¨ë“ˆì—ì„œ í˜¸ì¶œ

```python
from prism_monitor.modules.event_precursor.precursor import precursor
import pandas as pd

# ë°ì´í„° ì¤€ë¹„
datasets = {
    'welding': pd.read_csv('welding.csv'),
    'battery': pd.read_csv('battery.csv')
}

# ì‹¤í–‰
result = precursor(datasets)

# ê²°ê³¼ ì²˜ë¦¬
if 'error' in result:
    print(f"ì—ëŸ¬ ë°œìƒ: {result['error']}")
else:
    predicted_value = result['summary']['predicted_value']
    status = result['summary']['is_anomaly']

    if status == '2':
        print(f"âš ï¸ ìœ„í—˜: ì´ìƒ í™•ë¥  {predicted_value:.2%}")
        # ì•Œë¦¼ ì „ì†¡, ì ê²€ ìš”ì²­ ë“±
    elif status == '1':
        print(f"âš¡ ì£¼ì˜: ì´ìƒ ì§•í›„ ê°ì§€ ({predicted_value:.2%})")
        # ëª¨ë‹ˆí„°ë§ ê°•í™”
    else:
        print("âœ… ì •ìƒ")
```

---

### ì˜ˆì œ 3: ì»¤ìŠ¤í…€ ì„ê³„ê°’ ì„¤ì •

```python
from prism_monitor.modules.event_precursor._precursor import (
    load_and_explore_data,
    create_unified_dataset,
    prepare_features,
    create_time_series_data,
    create_lstm_model,
    train_lstm_model,
    predict_future_anomalies,
    generate_alerts
)
from sklearn.model_selection import train_test_split

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
datasets = load_and_explore_data('/path/to/data')
unified_df = create_unified_dataset(datasets)

# ... (ì¤‘ê°„ ê³¼ì • ìƒëµ)

# ì˜ˆì¸¡
probs, _ = predict_future_anomalies(model, X_test)

# ì»¤ìŠ¤í…€ ì„ê³„ê°’ìœ¼ë¡œ ê²½ê³  ìƒì„±
alerts = generate_alerts(
    probs,
    lot_numbers=timestamps,
    alert_threshold=0.85,    # ìœ„í—˜: 85% ì´ìƒ
    warning_threshold=0.60   # ì£¼ì˜: 60% ì´ìƒ
)

# ìœ„í—˜ ê²½ê³ ë§Œ í•„í„°ë§
critical_alerts = [a for a in alerts if a['alert_level'] == 'CRITICAL']
print(f"ìœ„í—˜ ê²½ê³ : {len(critical_alerts)}ê±´")
```

---

### ì˜ˆì œ 4: RUL ì˜ˆì¸¡ í™œìš©

```python
from prism_monitor.modules.event_precursor._precursor import (
    calculate_remaining_useful_life
)

# í˜„ì¬ ì„¤ë¹„ ìƒíƒœ (ìµœê·¼ 10 ìŠ¤í…)
current_sequence = X_test[0]  # shape: (10, num_features)

# RUL ì˜ˆì¸¡
rul = calculate_remaining_useful_life(
    model,
    current_sequence,
    max_horizon=200,       # ìµœëŒ€ 200 ìŠ¤í…
    failure_threshold=0.85  # 85% ì´ìƒì„ ê³ ì¥ìœ¼ë¡œ íŒë‹¨
)

print(f"ì˜ˆìƒ ì”ì—¬ ìˆ˜ëª…: {rul} ìŠ¤í…")

# ì˜ˆë°© ì •ë¹„ ê³„íš
if rul < 50:
    print("âš ï¸ ê¸´ê¸‰: ì¦‰ì‹œ ì ê²€ í•„ìš”")
elif rul < 100:
    print("âš¡ ì£¼ì˜: ì˜ˆë°© ì •ë¹„ ì¼ì • ìˆ˜ë¦½")
else:
    print("âœ… ì •ìƒ: ì •ê¸° ì ê²€ ìœ ì§€")
```

---

### ì˜ˆì œ 5: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜

```python
from prism_monitor.modules.event_precursor._precursor import (
    real_time_monitoring,
    create_mock_real_time_stream
)

# Mock ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ìƒì„±
data_stream = create_mock_real_time_stream(
    test_df,
    feature_cols,
    num_samples=100
)

# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
status = real_time_monitoring(
    model=trained_model,
    scaler=scaler,
    feature_cols=feature_cols,
    new_data_stream=data_stream,
    sequence_length=10,
    update_interval=1
)

print(f"ìµœì¢… ìƒíƒœ: {status}")
# '0': ì •ìƒ
# '1': ì£¼ì˜ ë°œìƒ
# '2': ìœ„í—˜ ë°œìƒ
```

---

## íŒŒë¼ë¯¸í„° ì„¤ì •

### ì‹œê³„ì—´ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… | ê¶Œì¥ ë²”ìœ„ |
|---------|-------|------|----------|
| `sequence_length` | 10 | ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ (ê³¼ê±° ë°ì´í„°) | 5-50 |
| `prediction_horizon` | 5 | ì˜ˆì¸¡ êµ¬ê°„ ê¸¸ì´ (ë¯¸ë˜ ìŠ¤í…) | 1-20 |
| `prediction_steps` | 5 | ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ì˜ ì˜ˆì¸¡ ìŠ¤í… ìˆ˜ | 1-20 |

**ì„ íƒ ê°€ì´ë“œ**:
- **ì§§ì€ ì£¼ê¸° ê³µì •** (ì´ˆ ë‹¨ìœ„): `sequence_length=5`, `prediction_horizon=3`
- **ì¼ë°˜ ê³µì •** (ë¶„ ë‹¨ìœ„): `sequence_length=10`, `prediction_horizon=5`
- **ëŠë¦° ê³µì •** (ì‹œê°„ ë‹¨ìœ„): `sequence_length=20`, `prediction_horizon=10`

---

### ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

#### ë‹¨ì¼ ì¶œë ¥ ëª¨ë¸

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|-------|------|
| `input_size` | auto | íŠ¹ì„± ê°œìˆ˜ (ìë™ ê³„ì‚°) |
| `hidden_size` | 64 | LSTM hidden state í¬ê¸° |
| `num_layers` | 2 | LSTM ë ˆì´ì–´ ìˆ˜ |
| `dropout` | 0.2 | Dropout ë¹„ìœ¨ |

#### ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|-------|------|
| `hidden_size` | 128 | LSTM hidden state í¬ê¸° (ë” í¼) |
| `num_layers` | 3 | LSTM ë ˆì´ì–´ ìˆ˜ (ë” ê¹ŠìŒ) |

---

### í•™ìŠµ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… | ê¶Œì¥ ê°’ |
|---------|-------|------|---------|
| `epochs` | 50 (ë‹¨ì¼) / 20 (ë‹¤ì¤‘) | í•™ìŠµ ì—í¬í¬ ìˆ˜ | 10-100 |
| `batch_size` | 32 | ë°°ì¹˜ í¬ê¸° | 16-128 |
| `learning_rate` | 0.001 | ì´ˆê¸° í•™ìŠµë¥  | 0.0001-0.01 |

**íŠœë‹ íŒ**:
- ë°ì´í„°ê°€ ë§ìœ¼ë©´: `batch_size` ì¦ê°€ (64, 128)
- ê³¼ì í•© ë°œìƒ ì‹œ: `dropout` ì¦ê°€ (0.3, 0.4), `epochs` ê°ì†Œ
- í•™ìŠµ ëŠë¦´ ë•Œ: `learning_rate` ì¦ê°€ (0.005, 0.01)

---

### ì„ê³„ê°’ íŒŒë¼ë¯¸í„°

#### ì´ìƒ ë ˆì´ë¸”ë§

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|-------|------|
| `percentile` | 90 | Z-score ê¸°ì¤€ ìƒìœ„ N% |

**ì¡°ì •**:
- ë” ì—„ê²©í•˜ê²Œ: `percentile=95` (ìƒìœ„ 5%ë§Œ ì´ìƒ)
- ë” ëŠìŠ¨í•˜ê²Œ: `percentile=85` (ìƒìœ„ 15% ì´ìƒ)

#### ê²½ê³  ìƒì„±

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|-------|------|
| `alert_threshold` | 0.7 | CRITICAL ê²½ê³  ì„ê³„ê°’ |
| `warning_threshold` | 0.5 | WARNING ê²½ê³  ì„ê³„ê°’ |

**ì‚°ì—…ë³„ ì¶”ì²œ**:
- **ì•ˆì „ ì¤‘ìš” (ë°˜ë„ì²´, í™”í•™)**: `alert=0.6`, `warning=0.4`
- **ì¼ë°˜ ì œì¡°**: `alert=0.7`, `warning=0.5`
- **ë¹„ìš© ë¯¼ê°**: `alert=0.8`, `warning=0.6`

#### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

| ìƒíƒœ | ê¸°ë³¸ ì„ê³„ê°’ | ì¡°ì • ê°€ëŠ¥ |
|-----|-----------|----------|
| ì •ìƒ (`'0'`) | < 0.3 | < `monitoring_warning` |
| ì£¼ì˜ (`'1'`) | 0.3 - 0.7 | `monitoring_warning` - `monitoring_critical` |
| ìœ„í—˜ (`'2'`) | â‰¥ 0.7 | â‰¥ `monitoring_critical` |

**ì½”ë“œì—ì„œ ì¡°ì •**:
```python
# real_time_monitoring í•¨ìˆ˜ ë‚´ë¶€ (608-646ì¤„)
if anomaly_prob >= 0.7:  # monitoring_critical
    ...
elif anomaly_prob >= 0.3:  # monitoring_warning
    ...
```

---

### ë°ì´í„° ë¶„í•  ë¹„ìœ¨

**ê¸°ë³¸ ì„¤ì •**:
```python
train_val_df, test_df = train_test_split(unified_df, test_size=0.1, shuffle=False)
train_df, val_df = train_test_split(train_val_df, test_size=0.1, shuffle=False)
```

**ë¹„ìœ¨**:
- Train: 81% (0.9 Ã— 0.9)
- Validation: 9% (0.9 Ã— 0.1)
- Test: 10%

**ì£¼ì˜**: `shuffle=False` í•„ìˆ˜ (ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€)

---

## ì°¸ê³  ì‚¬í•­

### ì„±ëŠ¥ ìµœì í™”

1. **GPU ì‚¬ìš©**:
```python
# ìë™ìœ¼ë¡œ GPU ê°ì§€ ë° ì‚¬ìš©
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

2. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**:
- GPU ë©”ëª¨ë¦¬ ì¶©ë¶„: `batch_size=128`
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: `batch_size=32`
- CPU ì „ìš©: `batch_size=16`

3. **ë°ì´í„° í¬ê¸°**:
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ: ë°ì´í„° ìƒ˜í”Œë§ ë˜ëŠ” ë¶„í•  ì²˜ë¦¬

---

### ì£¼ì˜ì‚¬í•­

1. **ë°ì´í„° ëˆ„ì¶œ ë°©ì§€**:
   - Train ë°ì´í„°ë¡œë§Œ í†µê³„ ê³„ì‚°
   - Val/TestëŠ” Train í†µê³„ ì‚¬ìš©

2. **ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€**:
   - `shuffle=False` í•„ìˆ˜
   - ì‹œê°„ìˆœ ì •ë ¬ í™•ì¸

3. **í´ë˜ìŠ¤ ë¶ˆê· í˜•**:
   - Weighted Loss ìë™ ì ìš©
   - í•„ìš” ì‹œ `percentile` ì¡°ì •

4. **ID ì»¬ëŸ¼ ì¸ì‹**:
   - í‘œì¤€ ID ì»¬ëŸ¼ ì‚¬ìš© ê¶Œì¥
   - ë¹„í‘œì¤€ ì»¬ëŸ¼ì€ `possible_id_cols`ì— ì¶”ê°€

---

### ì œí•œì‚¬í•­

1. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**:
   - ëŒ€ìš©ëŸ‰ ë°ì´í„° (> 1GB): ë¶„í•  ì²˜ë¦¬ í•„ìš”

2. **í•™ìŠµ ì‹œê°„**:
   - ë°ì´í„° í¬ê¸°, ëª¨ë¸ ë³µì¡ë„ì— ë¹„ë¡€
   - GPU ì‚¬ìš© ê°•ë ¥ ê¶Œì¥

3. **RUL ì˜ˆì¸¡ ì •í™•ë„**:
   - ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ (degradation_factor)
   - ì‹¤ì œ ë¬¼ë¦¬ ëª¨ë¸ ì ìš© ì‹œ ì •í™•ë„ í–¥ìƒ ê°€ëŠ¥

---

### í™•ì¥ ê°€ëŠ¥ì„±

1. **ë‹¤ë¥¸ ëª¨ë¸ ì ìš©**:
   - Transformer, GRU ë“±ìœ¼ë¡œ êµì²´ ê°€ëŠ¥

2. **ì•™ìƒë¸” ëª¨ë¸**:
   - ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°í•©

3. **ì˜¨ë¼ì¸ í•™ìŠµ**:
   - ì‹¤ì‹œê°„ ë°ì´í„°ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸

4. **ì„¤ëª… ê°€ëŠ¥ì„±**:
   - SHAP, LIME ë“± ì ìš© ê°€ëŠ¥

---

## ë¬¸ì˜ ë° ê¸°ì—¬

### ë²„ê·¸ ë¦¬í¬íŠ¸
ì´ìŠˆ ë°œê²¬ ì‹œ ë‹¤ìŒ ì •ë³´ì™€ í•¨ê»˜ ë³´ê³ :
- ë°ì´í„° í˜•ì‹ ë° í¬ê¸°
- ì—ëŸ¬ ë©”ì‹œì§€ ì „ë¬¸
- ì‹¤í–‰ í™˜ê²½ (Python ë²„ì „, PyTorch ë²„ì „)

### ê°œì„  ì œì•ˆ
- ìƒˆë¡œìš´ ê¸°ëŠ¥ ìš”ì²­
- ì„±ëŠ¥ ê°œì„  ì•„ì´ë””ì–´
- ë¬¸ì„œ ê°œì„ 

---

**ì‘ì„±ì¼**: 2025-10-24
**ë²„ì „**: 1.0.0
**ì‘ì„±ì**: PRISM-Monitor Development Team
