# Event Precursor Module - ìˆ˜ì • ë‚´ì—­

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” Event Precursor ëª¨ë“ˆì˜ ì£¼ìš” ìˆ˜ì • ì‚¬í•­ì„ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤.
LSTM ê¸°ë°˜ ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ëª¨ë“ˆì˜ ë²„ê·¸ ìˆ˜ì • ë° ê¸°ëŠ¥ ê°œì„  ì‚¬í•­ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

**ìˆ˜ì • ì¼ì**: 2025-10-24
**ìˆ˜ì •ì**: Jonghak Jang

### ìˆ˜ì •ëœ íŒŒì¼
- âœ… **_precursor.py**: í•µì‹¬ ë¡œì§ (5ê°€ì§€ ë²„ê·¸ ìˆ˜ì •)
- âœ… **precursor.py**: ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ (ì‚¬ìš©ì ê²½í—˜ ë° ì•ˆì •ì„± ê°œì„ )

---

## ğŸ¯ ìˆ˜ì • ëª©ì 

1. **ë°ì´í„° í˜¸í™˜ì„± ê°œì„ **: ë‹¤ì–‘í•œ ì‚°ì—…ë³„ ë°ì´í„°ì…‹ ì§€ì› (CELL_ID, LINE_ID ë“±)
2. **Critical ë²„ê·¸ ìˆ˜ì •**: ì‹œê³„ì—´ ì¸ë±ì‹± ì˜¤ë¥˜, ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¡°ê¸° ì¢…ë£Œ
3. **ì„±ëŠ¥ ê°œì„ **: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ë° ë°ì´í„° ëˆ„ì¶œ ë°©ì§€
4. **ì‚¬ìš©ì ê²½í—˜ ê°œì„ **: ì§„í–‰ ìƒí™© í‘œì‹œ, ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
5. **ì½”ë“œ í’ˆì§ˆ**: Production-ready ì½”ë“œë¡œ ê°œì„ 

---

## ğŸ”§ ì£¼ìš” ìˆ˜ì • ì‚¬í•­

ì´ **6ê°€ì§€** ìˆ˜ì • í•­ëª© (_precursor.py: 5ê°œ, precursor.py: 1ê°œ)

### 1. ì¥ë¹„ ID ì»¬ëŸ¼ ì‹ë³„ ë¡œì§ ê°œì„ 

**íŒŒì¼**: `_precursor.py`
**í•¨ìˆ˜**: `integrate_sensor_data()`, `create_unified_dataset()`

#### ë¬¸ì œì 
ê¸°ì¡´ ì½”ë“œëŠ” `SENSOR_ID`, `CHAMBER_ID`, `EQUIPMENT_ID`ë§Œ ì§€ì›í•˜ì—¬ ë‹¤ìŒ ë°ì´í„° íƒ€ì…ì„ ì²˜ë¦¬í•˜ì§€ ëª»í•¨:
- Battery ë°ì´í„°: `CELL_ID`
- Automotive ë°ì´í„°: `LINE_ID`

#### ìˆ˜ì • ì „
```python
equipment_col = None
if 'SENSOR_ID' in df_copy.columns:
    equipment_col = 'SENSOR_ID'
elif 'CHAMBER_ID' in df_copy.columns:
    equipment_col = 'CHAMBER_ID'
elif 'EQUIPMENT_ID' in df_copy.columns:
    equipment_col = 'EQUIPMENT_ID'
```

#### ìˆ˜ì • í›„
```python
# í¬ê´„ì ì¸ ID ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
equipment_col = None
possible_id_cols = ['SENSOR_ID', 'CHAMBER_ID', 'EQUIPMENT_ID', 'CELL_ID', 'LINE_ID']
for col in possible_id_cols:
    if col in df_copy.columns:
        equipment_col = col
        break

# íŒ¨í„´ ë§¤ì¹­: _IDë¡œ ëë‚˜ëŠ” ì»¬ëŸ¼ ìë™ íƒì§€
if equipment_col is None:
    id_cols = [col for col in df_copy.columns if col.endswith('_ID')]
    if id_cols:
        equipment_col = id_cols[0]
```

#### íš¨ê³¼
âœ… ëª¨ë“  ì‚°ì—… ì¹´í…Œê³ ë¦¬ ë°ì´í„° ì§€ì›
âœ… í™•ì¥ì„± í–¥ìƒ (ìƒˆë¡œìš´ ID ì»¬ëŸ¼ ìë™ ì¸ì‹)

---

### 2. ì‹œê³„ì—´ ë ˆì´ë¸” ì¸ë±ì‹± ì˜¤ë¥˜ ìˆ˜ì • (ğŸ”´ Critical)

**íŒŒì¼**: `_precursor.py`
**í•¨ìˆ˜**: `create_time_series_data()`
**ë¼ì¸**: 263

#### ë¬¸ì œì 
ì‹œê³„ì—´ ì…ë ¥ê³¼ ë ˆì´ë¸”ì˜ ì¸ë±ìŠ¤ ë§¤í•‘ì´ ì˜ëª»ë˜ì–´ í•™ìŠµ ë°ì´í„°ê°€ ì†ìƒë¨

#### ìˆ˜ì • ì „
```python
for i in range(sequence_length, len(feature_data) - prediction_horizon):
    X.append(feature_data[i-sequence_length:i])
    y.append(future_anomalies[i-sequence_length])  # âŒ ì˜ëª»ëœ ì¸ë±ì‹±
```

**ë¬¸ì œ**: `future_anomalies[i-sequence_length]`ëŠ” ì˜ëª»ëœ ë¯¸ë˜ ì‹œì ì„ ì°¸ì¡°

#### ìˆ˜ì • í›„
```python
for i in range(sequence_length, len(feature_data) - prediction_horizon):
    X.append(feature_data[i-sequence_length:i])
    y.append(future_anomalies[i])  # âœ… ì˜¬ë°”ë¥¸ ì¸ë±ì‹±
```

#### íš¨ê³¼
âœ… ì…ë ¥-ì¶œë ¥ ë§¤í•‘ì´ ì •í™•í•´ì ¸ ëª¨ë¸ í•™ìŠµ í’ˆì§ˆ í–¥ìƒ
âœ… ì˜ˆì¸¡ ì •í™•ë„ ê°œì„ 

---

### 3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¡°ê¸° ì¢…ë£Œ ë¬¸ì œ ìˆ˜ì • (ğŸ”´ Critical)

**íŒŒì¼**: `_precursor.py`
**í•¨ìˆ˜**: `real_time_monitoring()`
**ë¼ì¸**: 663-712

#### ë¬¸ì œì 
ì²« ë²ˆì§¸ ì˜ˆì¸¡ í›„ ì¦‰ì‹œ `return`í•˜ì—¬ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì´ ì‘ë™í•˜ì§€ ì•ŠìŒ

#### ìˆ˜ì • ì „
```python
for timestamp, new_data in new_data_stream:
    # ... ì˜ˆì¸¡ ìˆ˜í–‰ ...

    if anomaly_prob >= 0.7:
        print(f"[{timestamp}] ìœ„í—˜ ê²½ê³ ")
        return '2'  # âŒ ì¦‰ì‹œ ì¢…ë£Œ!
    elif anomaly_prob >= 0.3:
        return '1'  # âŒ í•œ ë²ˆë§Œ ì˜ˆì¸¡
```

**ë¬¸ì œ**: ì „ì²´ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì¤‘ ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ ì²˜ë¦¬

#### ìˆ˜ì • í›„
```python
max_anomaly_prob = 0.0
max_status = '0'

for timestamp, new_data in new_data_stream:
    # ... ì˜ˆì¸¡ ìˆ˜í–‰ ...

    if anomaly_prob >= 0.7:
        print(f"[{timestamp}] ğŸš¨ ìœ„í—˜ ê²½ê³ ")
        max_status = '2'
        max_anomaly_prob = max(max_anomaly_prob, anomaly_prob)
    elif anomaly_prob >= 0.3:
        print(f"[{timestamp}] âš ï¸ ì£¼ì˜")
        if max_status < '1':
            max_status = '1'
        max_anomaly_prob = max(max_anomaly_prob, anomaly_prob)
    else:
        print(f"[{timestamp}] âœ… ì•ˆì „")
        max_anomaly_prob = max(max_anomaly_prob, anomaly_prob)

# ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ í›„ ìµœê³  ìœ„í—˜ë„ ë°˜í™˜
print(f"\nëª¨ë‹ˆí„°ë§ ì™„ë£Œ: ìµœëŒ€ ì´ìƒ í™•ë¥  {max_anomaly_prob:.1%}, ìƒíƒœ: {max_status}")
return max_status
```

#### íš¨ê³¼
âœ… ì „ì²´ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ ì—°ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§
âœ… ìµœê³  ìœ„í—˜ë„ë¥¼ ì¶”ì í•˜ì—¬ ë°˜í™˜
âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ ì •ìƒ ì‘ë™

---

### 4. Z-score ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ë°©ì§€ (ğŸŸ¡ Warning)

**íŒŒì¼**: `_precursor.py`, `precursor.py`
**í•¨ìˆ˜**: `prepare_features()`
**ë¼ì¸**: 207-260

#### ë¬¸ì œì 
ì „ì²´ ë°ì´í„°(Train + Val + Test)ì˜ í†µê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ Z-scoreë¥¼ ê³„ì‚°í•˜ë©´ ë¯¸ë˜ ì •ë³´ê°€ ê³¼ê±°ì— ëˆ„ì¶œë¨

#### ìˆ˜ì • ì „
```python
def prepare_features(df):
    # ì „ì²´ ë°ì´í„°ì˜ í‰ê· /í‘œì¤€í¸ì°¨ ì‚¬ìš©
    z_scores = np.abs((feature_data - feature_data.mean()) / feature_data.std())
    # ... ì´ìƒ íŒì • ...
```

**ë¬¸ì œ**: Test ë°ì´í„°ì˜ ì •ë³´ê°€ Train ë°ì´í„° ì „ì²˜ë¦¬ì— ì˜í–¥

#### ìˆ˜ì • í›„
```python
def prepare_features(df, train_stats=None):
    """
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        train_stats: í•™ìŠµ ë°ì´í„°ì˜ í†µê³„ (mean, std). Noneì´ë©´ í˜„ì¬ ë°ì´í„°ë¡œ ê³„ì‚°
    """
    if train_stats is None:
        # Train ë°ì´í„°ì¸ ê²½ìš°: í†µê³„ ê³„ì‚°
        mean_vals = feature_data.mean()
        std_vals = feature_data.std() + 1e-8
        train_stats = {'mean': mean_vals, 'std': std_vals}
    else:
        # Val/Test ë°ì´í„°ì¸ ê²½ìš°: Train í†µê³„ ì‚¬ìš©
        mean_vals = train_stats['mean']
        std_vals = train_stats['std']

    # Z-score ê³„ì‚°
    z_scores = np.abs((feature_data - mean_vals) / std_vals).mean(axis=1)
    # ...

    return df_processed, feature_cols, scaler, train_stats
```

**ì‚¬ìš© ì˜ˆì‹œ** (`precursor.py`):
```python
# Train ë°ì´í„°ë¡œ í†µê³„ ê³„ì‚°
train_df, feature_cols, scaler, train_stats = prepare_features(train_df, train_stats=None)

# Val/Test ë°ì´í„°ëŠ” Train í†µê³„ ì‚¬ìš©
val_df, _, _, _ = prepare_features(val_df, train_stats=train_stats)
test_df, _, _, _ = prepare_features(test_df, train_stats=train_stats)
```

#### íš¨ê³¼
âœ… ë°ì´í„° ëˆ„ì¶œ ë°©ì§€ë¡œ ëª¨ë¸ ì„±ëŠ¥ ì •í™•íˆ í‰ê°€
âœ… ì‹¤ì œ ìš´ì˜ í™˜ê²½ê³¼ ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ í•™ìŠµ
âœ… Overfitting ê°€ëŠ¥ì„± ê°ì†Œ

---

### 5. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (ğŸŸ¡ Warning)

**íŒŒì¼**: `_precursor.py`
**í•¨ìˆ˜**: `train_lstm_model()`
**ë¼ì¸**: 391-422

#### ë¬¸ì œì 
ì´ìƒ ë°ì´í„°ê°€ 10%ë¡œ ì†Œìˆ˜ì¸ë°, ê°€ì¤‘ì¹˜ ì—†ì´ í•™ìŠµí•˜ë©´ ëª¨ë¸ì´ ì •ìƒ ë°ì´í„°ë§Œ í•™ìŠµ

#### ìˆ˜ì • ì „
```python
criterion = nn.BCELoss()  # ê°€ì¤‘ì¹˜ ì—†ìŒ
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# í•™ìŠµ ë£¨í”„
for batch_X, batch_y in train_loader:
    outputs = model(batch_X).squeeze(-1)
    loss = criterion(outputs, batch_y)  # âŒ ë¶ˆê· í˜• ë¯¸ì²˜ë¦¬
```

#### ìˆ˜ì • í›„
```python
# pos_weight ê³„ì‚°
num_pos = (y_train == 1).sum()
num_neg = (y_train == 0).sum()
if num_pos > 0:
    pos_weight = torch.tensor([num_neg / num_pos]).to(device)
    print(f"í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬: pos_weight={pos_weight.item():.2f}")
else:
    pos_weight = torch.tensor([1.0]).to(device)

# í•™ìŠµ ë£¨í”„ì—ì„œ weighted loss ì ìš©
for batch_X, batch_y in train_loader:
    outputs = model(batch_X).squeeze(-1)

    # í´ë˜ìŠ¤ ë¶ˆê· í˜• ê³ ë ¤í•œ ê°€ì¤‘ì¹˜
    batch_weights = torch.where(batch_y == 1, pos_weight.squeeze(), torch.tensor(1.0).to(device))
    loss = nn.functional.binary_cross_entropy(outputs, batch_y, weight=batch_weights)
```

**ì˜ˆì‹œ**: ì •ìƒ 900ê°œ, ì´ìƒ 100ê°œì¸ ê²½ìš°
- `pos_weight = 900 / 100 = 9.0`
- ì´ìƒ ìƒ˜í”Œì˜ ì†ì‹¤ì— 9ë°° ê°€ì¤‘ì¹˜ ì ìš©

#### íš¨ê³¼
âœ… ì†Œìˆ˜ í´ë˜ìŠ¤(ì´ìƒ ë°ì´í„°)ì— ë” ë§ì€ ê°€ì¤‘ì¹˜
âœ… ì´ìƒ íƒì§€ ì„±ëŠ¥ í–¥ìƒ
âœ… False Negative ê°ì†Œ

---

### 6. precursor.py ì¸í„°í˜ì´ìŠ¤ ê°œì„ 

**íŒŒì¼**: `precursor.py`
**í•¨ìˆ˜**: `main()`, `precursor()`
**ì „ì²´ íŒŒì¼ ë¦¬íŒ©í† ë§**

#### ê°œìš”
`precursor.py`ëŠ” `_precursor.py`ì˜ í•¨ìˆ˜ë“¤ì„ í˜¸ì¶œí•˜ëŠ” ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤. `_precursor.py`ì˜ ìˆ˜ì •ì‚¬í•­(íŠ¹íˆ `prepare_features`ì˜ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½)ê³¼ ì—°ë™ë˜ë„ë¡ ì „ë©´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.

---

#### 6-1. main() í•¨ìˆ˜ ê°œì„ 

**ëª©ì **: ë¡œì»¬ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸

#### ìˆ˜ì • ì „
```python
def main():
    DATA_BASE_PATH = '../../data/Industrial_DB_sample/'
    print("ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬")
    all_datasets = load_and_explore_data(DATA_BASE_PATH)
    if not all_datasets:
        print("ë°ì´í„° ë¡œë”© ì‹¤íŒ¨.")
        return

    unified_df = create_unified_dataset(all_datasets)
    if unified_df.empty:
        print("í†µí•© ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨.")
        return

    processed_df, feature_cols, scaler = prepare_features(unified_df)  # âŒ êµ¬ ì‹œê·¸ë‹ˆì²˜
    print("=" * 40, "\n")

    train_val_df, test_df = train_test_split(processed_df, test_size=0.1, shuffle=False)
    train_df, val_df = train_test_split(train_val_df, test_size=0.1, shuffle=False)

    # ... ëª¨ë¸ ì‹¤í–‰ ...
```

**ë¬¸ì œì :**
- âŒ `prepare_features` í˜¸ì¶œì´ ë°ì´í„° ë¶„í•  ì „ì— ì‹¤í–‰ â†’ ë°ì´í„° ëˆ„ì¶œ
- âŒ ì§„í–‰ ìƒí™©ì„ ì•Œ ìˆ˜ ì—†ìŒ
- âŒ ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±
- âŒ ë°˜í™˜ê°’ ì´ˆê¸°í™” ëˆ„ë½ (`anomaly_status` ë¯¸ì •ì˜ ê°€ëŠ¥)

#### ìˆ˜ì • í›„
```python
def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    - ë¡œì»¬ ë°ì´í„° ê²½ë¡œì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    DATA_BASE_PATH = '../../data/Industrial_DB_sample/'

    print("=" * 60)
    print("ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ëª¨ë“ˆ ì‹œì‘")
    print("=" * 60)

    # 1. ë°ì´í„° ë¡œë“œ
    print("\n[1/6] ë°ì´í„° ë¡œë”©...")
    all_datasets = load_and_explore_data(DATA_BASE_PATH)
    if not all_datasets:
        print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨.")
        return None  # âœ… ëª…ì‹œì  None ë°˜í™˜

    # 2. ë°ì´í„° í†µí•©
    print("\n[2/6] ë°ì´í„° í†µí•©...")
    unified_df = create_unified_dataset(all_datasets)
    if unified_df.empty:
        print("âŒ í†µí•© ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨.")
        return None

    print(f"âœ… í†µí•© ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {unified_df.shape}")

    # 3. ë°ì´í„° ë¶„í•  (ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€)
    print("\n[3/6] ë°ì´í„° ë¶„í•  (Train/Val/Test)...")
    train_val_df, test_df = train_test_split(unified_df, test_size=0.1, shuffle=False)
    train_df, val_df = train_test_split(train_val_df, test_size=0.1, shuffle=False)

    # 4. íŠ¹ì„± ì „ì²˜ë¦¬ (ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ë°©ì§€)
    print("\n[4/6] íŠ¹ì„± ì „ì²˜ë¦¬ ë° ì´ìƒ ë ˆì´ë¸”ë§...")
    print("  - Train ë°ì´í„°ë¡œ í†µê³„ ê³„ì‚°")
    train_df, feature_cols, scaler, train_stats = prepare_features(train_df, train_stats=None)

    print("  - Val/Test ë°ì´í„°ëŠ” Train í†µê³„ ì‚¬ìš© (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)")
    val_df, _, _, _ = prepare_features(val_df, train_stats=train_stats)
    test_df, _, _, _ = prepare_features(test_df, train_stats=train_stats)

    print(f"\nâœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
    print(f"  - í•™ìŠµ ë°ì´í„°: {train_df.shape}")
    print(f"  - ê²€ì¦ ë°ì´í„°: {val_df.shape}")
    print(f"  - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_df.shape}")
    print(f"  - íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}")
    print("=" * 60)

    # 5. ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    print("\n[5/6] ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡...")
    # ... (ì‹œë‚˜ë¦¬ì˜¤ 1, 2 ì‹¤í–‰)

    # 6. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    print("\n[6/6] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§...")
    anomaly_status = '0'  # âœ… ê¸°ë³¸ê°’ ì„¤ì •

    if trained_model is not None:
        print("\n>> ì‹œë‚˜ë¦¬ì˜¤ 3: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜")
        anomaly_status = run_real_time_monitoring_scenario(
            trained_model, model_scaler, feature_cols, test_df
        )
    else:
        print("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ì–´ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    # ê²°ê³¼ ë°˜í™˜
    print("\n" + "=" * 60)
    print("âœ… ì´ìƒ ì§•í›„ ì˜ˆì¸¡ ì™„ë£Œ")
    print("=" * 60)

    return {
        'summary': {
            'predicted_value': pred_value,
            'is_anomaly': anomaly_status
        }
    }
```

**ê°œì„  ì‚¬í•­:**
- âœ… **6ë‹¨ê³„ ì§„í–‰ í‘œì‹œ**: ì‚¬ìš©ìê°€ í˜„ì¬ ì§„í–‰ ìƒí™© íŒŒì•… ê°€ëŠ¥
- âœ… **ë°ì´í„° ë¶„í•  í›„ ì „ì²˜ë¦¬**: ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ë°©ì§€
- âœ… **train_stats ì „ë‹¬**: Val/TestëŠ” Train í†µê³„ ì‚¬ìš©
- âœ… **ëª…í™•í•œ ë¡œê¹…**: ê° ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ì¶œë ¥
- âœ… **ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”**: None ë°˜í™˜ìœ¼ë¡œ ì‹¤íŒ¨ ëª…ì‹œ
- âœ… **ê¸°ë³¸ê°’ ì„¤ì •**: anomaly_status ì´ˆê¸°í™”ë¡œ ì•ˆì „ì„± í–¥ìƒ

---

#### 6-2. precursor() í•¨ìˆ˜ ê°œì„ 

**ëª©ì **: ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ API í•¨ìˆ˜

#### ìˆ˜ì • ì „
```python
def precursor(datasets):
    unified_df = create_unified_dataset(datasets)
    processed_df, feature_cols, scaler = prepare_features(unified_df)  # âŒ êµ¬ ì‹œê·¸ë‹ˆì²˜
    train_val_df, test_df = train_test_split(processed_df, test_size=0.1, shuffle=False)
    train_df, val_df = train_test_split(train_val_df, test_size=0.1, shuffle=False)
    trained_model, model_scaler = run_single_output_scenario(train_df, val_df, test_df, feature_cols, scaler)
    pred_value = run_multi_output_scenario(train_df, val_df, test_df, feature_cols)
    anomaly_status = run_real_time_monitoring_scenario(trained_model, model_scaler, feature_cols, test_df)
    return {
        'summary': {
            'predicted_value': float(pred_value[0]),  # âŒ pred_valueê°€ Noneì¼ ìˆ˜ ìˆìŒ
            'is_anomaly': anomaly_status
        }
    }
```

**ë¬¸ì œì :**
- âŒ docstring ì—†ìŒ (íŒŒë¼ë¯¸í„°/ë°˜í™˜ê°’ ì„¤ëª… ë¶€ì¡±)
- âŒ ë¹ˆ ë°ì´í„°ì…‹ ì²˜ë¦¬ ì—†ìŒ
- âŒ `pred_value`ê°€ Noneì¸ ê²½ìš° ì˜¤ë¥˜ ë°œìƒ
- âŒ ì—ëŸ¬ ë°œìƒ ì‹œ ì²˜ë¦¬ ë¶€ì¡±

#### ìˆ˜ì • í›„
```python
def precursor(datasets):
    """
    ì™¸ë¶€ì—ì„œ í˜¸ì¶œë˜ëŠ” ì´ìƒ ì§•í›„ ì˜ˆì¸¡ í•¨ìˆ˜

    Args:
        datasets: dict - load_and_explore_data()ë¡œ ë¡œë“œëœ ë°ì´í„°ì…‹ ë”•ì…”ë„ˆë¦¬
                  ì˜ˆ: {'semiconductor_etch_002': DataFrame, ...}

    Returns:
        dict: ì˜ˆì¸¡ ê²°ê³¼
            {
                'summary': {
                    'predicted_value': float - ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’,
                    'is_anomaly': str - '0': ì •ìƒ, '1': ê²½ê³ , '2': ìœ„í—˜
                }
            }
    """
    print("=" * 60)
    print("Precursor ëª¨ë“ˆ ì‹¤í–‰ (ì™¸ë¶€ í˜¸ì¶œ)")
    print("=" * 60)

    # 1. ë°ì´í„° í†µí•©
    print("\n[1/5] ë°ì´í„° í†µí•©...")
    unified_df = create_unified_dataset(datasets)

    if unified_df.empty:
        print("âŒ í†µí•© ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return {
            'summary': {
                'predicted_value': 0.0,
                'is_anomaly': '0'
            },
            'error': 'ë°ì´í„°ì…‹ í†µí•© ì‹¤íŒ¨'  # âœ… ì—ëŸ¬ ì •ë³´ í¬í•¨
        }

    print(f"âœ… í†µí•© ë°ì´í„°ì…‹: {unified_df.shape}")

    # 2. ë°ì´í„° ë¶„í•  (ì‹œê³„ì—´ ìˆœì„œ ìœ ì§€)
    print("\n[2/5] ë°ì´í„° ë¶„í• ...")
    train_val_df, test_df = train_test_split(unified_df, test_size=0.1, shuffle=False)
    train_df, val_df = train_test_split(train_val_df, test_size=0.1, shuffle=False)

    # 3. íŠ¹ì„± ì „ì²˜ë¦¬ (ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ ë°©ì§€)
    print("\n[3/5] íŠ¹ì„± ì „ì²˜ë¦¬...")
    # Train ë°ì´í„°ë¡œ í†µê³„ ê³„ì‚°
    train_df, feature_cols, scaler, train_stats = prepare_features(train_df, train_stats=None)
    # Val/Test ë°ì´í„°ëŠ” Train í†µê³„ ì‚¬ìš©
    val_df, _, _, _ = prepare_features(val_df, train_stats=train_stats)
    test_df, _, _, _ = prepare_features(test_df, train_stats=train_stats)

    print(f"âœ… íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}")

    # 4. ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    print("\n[4/5] ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡...")
    print("  - ë‹¨ì¼ ì¶œë ¥ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    trained_model, model_scaler = run_single_output_scenario(
        train_df, val_df, test_df, feature_cols, scaler
    )

    print("  - ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    pred_value = run_multi_output_scenario(train_df, val_df, test_df, feature_cols)

    # 5. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    print("\n[5/5] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§...")
    anomaly_status = '0'  # âœ… ê¸°ë³¸ê°’

    if trained_model is not None:
        anomaly_status = run_real_time_monitoring_scenario(
            trained_model, model_scaler, feature_cols, test_df
        )
    else:
        print("âš ï¸ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ë°˜í™˜")

    # ê²°ê³¼ ë°˜í™˜
    print("\n" + "=" * 60)
    print(f"âœ… Precursor ì™„ë£Œ - ì´ìƒ ìƒíƒœ: {anomaly_status}")
    print("=" * 60)

    return {
        'summary': {
            'predicted_value': float(pred_value[0]) if pred_value is not None else 0.0,  # âœ… None ì²´í¬
            'is_anomaly': anomaly_status
        }
    }
```

**ê°œì„  ì‚¬í•­:**
- âœ… **ìƒì„¸í•œ docstring**: íŒŒë¼ë¯¸í„°ì™€ ë°˜í™˜ê°’ ì„¤ëª…
- âœ… **ë¹ˆ ë°ì´í„°ì…‹ ì²˜ë¦¬**: ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨ ì‘ë‹µ ë°˜í™˜
- âœ… **None ì•ˆì „ì„±**: `pred_value is not None` ì²´í¬
- âœ… **5ë‹¨ê³„ ì§„í–‰ í‘œì‹œ**: ì™¸ë¶€ í˜¸ì¶œ ì‹œì—ë„ ëª…í™•í•œ ì§„í–‰ ìƒí™©
- âœ… **ê¸°ë³¸ê°’ ì„¤ì •**: ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ ì‹œì—ë„ ì•ˆì „í•œ ë°˜í™˜
- âœ… **ì—ëŸ¬ ì •ë³´ ì œê³µ**: `error` í‚¤ë¡œ ì‹¤íŒ¨ ì›ì¸ ì „ë‹¬

---

#### 6-3. ì „ì²´ ì‹¤í–‰ íë¦„ ê°œì„ 

**ê°œì„ ëœ íŒŒì´í”„ë¼ì¸:**
```
ì™¸ë¶€ í˜¸ì¶œ: precursor(datasets)
    â†“
[1/5] ë°ì´í„° í†µí•©
    â”œâ”€ unified_df = create_unified_dataset()
    â””â”€ ë¹ˆ ë°ì´í„°ì…‹ ì²´í¬ âœ…
    â†“
[2/5] ë°ì´í„° ë¶„í•  (shuffle=False)
    â”œâ”€ Train: 80%
    â”œâ”€ Val: 10%
    â””â”€ Test: 10%
    â†“
[3/5] íŠ¹ì„± ì „ì²˜ë¦¬ (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€ âœ…)
    â”œâ”€ Train: prepare_features(train_stats=None) â† í†µê³„ í•™ìŠµ
    â”œâ”€ Val: prepare_features(train_stats=...) â† Train í†µê³„ ì‚¬ìš©
    â””â”€ Test: prepare_features(train_stats=...) â† Train í†µê³„ ì‚¬ìš©
    â†“
[4/5] ëª¨ë¸ í•™ìŠµ
    â”œâ”€ ë‹¨ì¼ ì¶œë ¥ LSTM
    â””â”€ ë‹¤ì¤‘ ì¶œë ¥ LSTM
    â†“
[5/5] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    â””â”€ ìµœê³  ìœ„í—˜ë„ ë°˜í™˜ ('0', '1', '2')
    â†“
ê²°ê³¼ ë°˜í™˜ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨ âœ…)
```

---

#### íš¨ê³¼
âœ… **_precursor.pyì™€ ì™„ë²½ ì—°ë™**: `prepare_features` ì‹œê·¸ë‹ˆì²˜ ë³€ê²½ ë°˜ì˜
âœ… **ë°ì´í„° ëˆ„ì¶œ ë°©ì§€**: Train í†µê³„ë§Œ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
âœ… **ì‚¬ìš©ì ê²½í—˜ ê°œì„ **: 6ë‹¨ê³„/5ë‹¨ê³„ ì§„í–‰ í‘œì‹œ
âœ… **ì•ˆì •ì„± í–¥ìƒ**: None ì²´í¬, ê¸°ë³¸ê°’ ì„¤ì •, ì—ëŸ¬ ì²˜ë¦¬
âœ… **ë¬¸ì„œí™” ê°œì„ **: ìƒì„¸í•œ docstring ë° ì£¼ì„
âœ… **Production-ready**: ì™¸ë¶€ APIë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€

---

## ğŸ“Š ìˆ˜ì • ì „í›„ ë¹„êµ

| í•­ëª© | ìˆ˜ì • ì „ | ìˆ˜ì • í›„ |
|------|---------|---------|
| **ì§€ì› ë°ì´í„° íƒ€ì…** | 3ê°œ (SENSOR_ID, CHAMBER_ID, EQUIPMENT_ID) | 5ê°œ+ (CELL_ID, LINE_ID ì¶”ê°€, íŒ¨í„´ ë§¤ì¹­) |
| **ì‹œê³„ì—´ ë§¤í•‘** | âŒ ì˜ëª»ëœ ì¸ë±ì‹± | âœ… ì •í™•í•œ ì…ë ¥-ì¶œë ¥ ë§¤í•‘ |
| **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§** | âŒ ì²« ìƒ˜í”Œë§Œ ì²˜ë¦¬ | âœ… ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì—°ì† ëª¨ë‹ˆí„°ë§ |
| **ë°ì´í„° ëˆ„ì¶œ** | âŒ Train/Test í†µê³„ í˜¼ìš© | âœ… Train í†µê³„ë§Œ ì‚¬ìš© (prepare_features ê°œì„ ) |
| **í´ë˜ìŠ¤ ë¶ˆê· í˜•** | âŒ ë¯¸ì²˜ë¦¬ | âœ… Weighted Loss ì ìš© |
| **precursor.py** | âŒ ì§„í–‰ ìƒí™© ë¶ˆëª…í™•, ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡± | âœ… 6ë‹¨ê³„/5ë‹¨ê³„ ì§„í–‰ í‘œì‹œ, ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” |
| **API ì•ˆì •ì„±** | âŒ None ì²´í¬ ì—†ìŒ, docstring ë¶€ì¡± | âœ… None ì•ˆì „ì„±, ìƒì„¸í•œ docstring |
| **ì½”ë“œ ìƒíƒœ** | ğŸ”´ Critical ë²„ê·¸ ì¡´ì¬ | âœ… Production-ready |

---

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
PRISM-Monitor/
â”œâ”€â”€ prism_monitor/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â””â”€â”€ event_precursor/
â”‚   â”‚       â”œâ”€â”€ _precursor.py          # í•µì‹¬ ë¡œì§ (âœ… ìˆ˜ì •ë¨)
â”‚   â”‚       â”œâ”€â”€ precursor.py           # ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ (âœ… ìˆ˜ì •ë¨)
â”‚   â”‚       â”œâ”€â”€ README.md              # ğŸ“– ìˆ˜ì • ë‚´ì—­ ë¬¸ì„œ (ì´ ë¬¸ì„œ)
â”‚   â”‚       â””â”€â”€ _precursor_save.py     # ë°±ì—… (ìˆ˜ì • ì „)
â”‚   â””â”€â”€ test-scenarios/
â”‚       â””â”€â”€ test_data/
â”‚           â”œâ”€â”€ semiconductor/         # ë°˜ë„ì²´ ê³µì • ë°ì´í„° (4ê°œ CSV)
â”‚           â”œâ”€â”€ battery/               # ë°°í„°ë¦¬ ì œì¡° ë°ì´í„° (4ê°œ CSV)
â”‚           â”œâ”€â”€ automotive/            # ìë™ì°¨ ì¡°ë¦½ ë°ì´í„° (4ê°œ CSV)
â”‚           â”œâ”€â”€ chemical/              # í™”í•™ ê³µì • ë°ì´í„° (4ê°œ CSV)
â”‚           â””â”€â”€ steel/                 # ì² ê°• ì œì¡° ë°ì´í„° (4ê°œ CSV)
â””â”€â”€ modification_test.py               # ğŸ§ª í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ì‹ ê·œ)
```

### ì£¼ìš” íŒŒì¼ ì„¤ëª…

- **_precursor.py**: ë°ì´í„° ë¡œë”©, ì „ì²˜ë¦¬, LSTM ëª¨ë¸ í•™ìŠµ, ì˜ˆì¸¡ ë“± í•µì‹¬ ë¡œì§ (5ê°€ì§€ ì£¼ìš” ë²„ê·¸ ìˆ˜ì •)
- **precursor.py**: ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ë©”ì¸ ì¸í„°í˜ì´ìŠ¤ (main(), precursor() í•¨ìˆ˜)
- **modification_test.py**: ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ìš© ìŠ¤í¬ë¦½íŠ¸
- **README.md**: ëª¨ë“  ìˆ˜ì • ë‚´ì—­ê³¼ ì‚¬ìš©ë²•ì„ ë‹´ì€ ë¬¸ì„œ

---

## ğŸ› ìˆ˜ì • í•­ëª© ìš°ì„ ìˆœìœ„ ë¶„ë¥˜

### ğŸ”´ Critical (ì¹˜ëª…ì ) - _precursor.py
1. âœ… **ì‹œê³„ì—´ ë ˆì´ë¸” ì¸ë±ì‹± ì˜¤ë¥˜** - í•™ìŠµ ë°ì´í„° ì†ìƒ
2. âœ… **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¡°ê¸° ì¢…ë£Œ** - ê¸°ëŠ¥ ë¯¸ì‘ë™

### ğŸŸ¡ Warning (ì¤‘ìš”) - _precursor.py
3. âœ… **Z-score ë¯¸ë˜ ì •ë³´ ëˆ„ì¶œ** - ê³¼ì í•© ê°€ëŠ¥ì„±
4. âœ… **í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¯¸ì²˜ë¦¬** - í•™ìŠµ í’ˆì§ˆ ì €í•˜

### ğŸŸ¢ Improvement (ê°œì„ )
5. âœ… **ì¥ë¹„ ID ì»¬ëŸ¼ ì‹ë³„** (_precursor.py) - ë°ì´í„° í˜¸í™˜ì„± í–¥ìƒ
6. âœ… **precursor.py ì¸í„°í˜ì´ìŠ¤ ê°œì„ ** (precursor.py) - ì‚¬ìš©ì ê²½í—˜ ë° ì•ˆì •ì„± í–¥ìƒ
   - main() í•¨ìˆ˜: 6ë‹¨ê³„ ì§„í–‰ í‘œì‹œ, ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
   - precursor() í•¨ìˆ˜: docstring ì¶”ê°€, None ì•ˆì „ì„±, 5ë‹¨ê³„ ì§„í–‰ í‘œì‹œ

---

## ğŸ” í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

ìˆ˜ì • í›„ ë‹¤ìŒ í•­ëª©ë“¤ì´ ì •ìƒ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤:

### _precursor.py ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
- [ ] ëª¨ë“  ì‚°ì—… ì¹´í…Œê³ ë¦¬ ë°ì´í„° ë¡œë“œ (semiconductor, battery, automotive, chemical, steel)
- [ ] CELL_ID, LINE_ID ë“± ë‹¤ì–‘í•œ ID ì»¬ëŸ¼ ì¸ì‹
- [ ] ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì‹œ ì •í™•í•œ ì…ë ¥-ì¶œë ¥ ë§¤í•‘
- [ ] Train/Val/Test ë¶„ë¦¬ í›„ í†µê³„ ê³„ì‚° (ë°ì´í„° ëˆ„ì¶œ ë°©ì§€)
- [ ] í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (pos_weight ê³„ì‚° ë° ì ìš©)
- [ ] ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
- [ ] ìµœê³  ìœ„í—˜ë„ ë°˜í™˜ ('0', '1', '2')

### precursor.py ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸
- [ ] main() í•¨ìˆ˜: 6ë‹¨ê³„ ì§„í–‰ í‘œì‹œ ì •ìƒ ì¶œë ¥
- [ ] precursor() í•¨ìˆ˜: 5ë‹¨ê³„ ì§„í–‰ í‘œì‹œ ì •ìƒ ì¶œë ¥
- [ ] ë¹ˆ ë°ì´í„°ì…‹ ì…ë ¥ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨ ì‘ë‹µ ë°˜í™˜
- [ ] pred_valueê°€ Noneì¼ ë•Œ 0.0ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ë°˜í™˜
- [ ] ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ ('0')
- [ ] ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° ê²€ì¦: {'summary': {'predicted_value': float, 'is_anomaly': str}}

**í…ŒìŠ¤íŠ¸ ë°©ë²•**: `python modification_test.py` ì‹¤í–‰

---

## ğŸ“– ì°¸ê³  ìë£Œ

### ì´ìƒ ì§•í›„ ì˜ˆì¸¡ íë¦„
```
[ë°ì´í„° ë¡œë“œ]
    â†“ (ë‹¤ì–‘í•œ ID ì»¬ëŸ¼ ì§€ì›)
[ë°ì´í„° í†µí•©]
    â†“
[ë°ì´í„° ë¶„í• ] (Train/Val/Test, shuffle=False)
    â†“
[íŠ¹ì„± ì „ì²˜ë¦¬] (Train í†µê³„ ê³„ì‚°, Val/TestëŠ” Train í†µê³„ ì‚¬ìš©)
    â”œâ”€ Z-score ê¸°ë°˜ ì´ìƒ ë ˆì´ë¸”ë§
    â””â”€ StandardScaler ì •ê·œí™”
    â†“
[ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±] (ì •í™•í•œ ì¸ë±ì‹±)
    â”œâ”€ ì…ë ¥: [t-10 ~ t-1] ê³¼ê±° 10 ìŠ¤í…
    â””â”€ ì¶œë ¥: [t+1 ~ t+5] ë¯¸ë˜ 5 ìŠ¤í… ë‚´ ì´ìƒ ì—¬ë¶€
    â†“
[LSTM í•™ìŠµ] (Weighted BCE Loss)
    â”œâ”€ 2-layer LSTM (hidden=64)
    â””â”€ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
    â†“
[ì˜ˆì¸¡ ë° ê²½ê³ ]
    â”œâ”€ í™•ë¥  â‰¥ 0.7: ğŸš¨ CRITICAL
    â”œâ”€ í™•ë¥  â‰¥ 0.3: âš ï¸ WARNING
    â””â”€ í™•ë¥  < 0.3: âœ… NORMAL
    â†“
[ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§] (ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬)
    â””â”€ ìµœê³  ìœ„í—˜ë„ ë°˜í™˜
```

---


## ğŸ“Š ì „ì²´ ìˆ˜ì • ìš”ì•½

### _precursor.py (í•µì‹¬ ë¡œì§)
| ë²ˆí˜¸ | ìˆ˜ì • í•­ëª© | ìš°ì„ ìˆœìœ„ | ì˜í–¥ë„ | ìƒíƒœ |
|-----|----------|---------|-------|-----|
| 1 | ì¥ë¹„ ID ì»¬ëŸ¼ ì‹ë³„ ê°œì„  | ğŸŸ¢ Improvement | ë°ì´í„° í˜¸í™˜ì„± | âœ… |
| 2 | ì‹œê³„ì—´ ë ˆì´ë¸” ì¸ë±ì‹± ìˆ˜ì • | ğŸ”´ Critical | í•™ìŠµ í’ˆì§ˆ | âœ… |
| 3 | ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì¡°ê¸° ì¢…ë£Œ ìˆ˜ì • | ğŸ”´ Critical | ê¸°ëŠ¥ ì‘ë™ | âœ… |
| 4 | Z-score ë°ì´í„° ëˆ„ì¶œ ë°©ì§€ | ğŸŸ¡ Warning | ëª¨ë¸ ì„±ëŠ¥ | âœ… |
| 5 | í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ | ğŸŸ¡ Warning | ì˜ˆì¸¡ ì •í™•ë„ | âœ… |

### precursor.py (ì¸í„°í˜ì´ìŠ¤)
| ë²ˆí˜¸ | ìˆ˜ì • í•­ëª© | ìš°ì„ ìˆœìœ„ | ì˜í–¥ë„ | ìƒíƒœ |
|-----|----------|---------|-------|-----|
| 6 | main() & precursor() í•¨ìˆ˜ ê°œì„  | ğŸŸ¢ Improvement | UX & ì•ˆì •ì„± | âœ… |

### í…ŒìŠ¤íŠ¸
- âœ… **modification_test.py**: ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±