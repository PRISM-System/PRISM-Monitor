"""
Dashboard.py ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì£¼ìš” í•¨ìˆ˜ë“¤ì´ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
"""
import sys
import logging
from pathlib import Path

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).resolve().parent
REPO_ROOT = SCRIPT_DIR.parent.parent.parent

# dashboard ëª¨ë“ˆ import
from dashboard import (
    _iter_csv_datasets,
    _tf_init_devices,
    build_anomaly_registry_from_root,
    default_state_fn,
    _resolve_state,
    _to_python_scalar,
    DEFAULT_TEST_DATA_DIR,
    DEFAULT_MODELS_ROOT,
)

logging.basicConfig(
    level=logging.INFO,
    format="[%(levelname)s] %(message)s",
)

def print_section(title: str):
    """ì„¹ì…˜ êµ¬ë¶„ì„  ì¶œë ¥"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def test_tf_device_init():
    """TensorFlow ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    print_section("TEST 1: TensorFlow ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™”")

    try:
        _tf_init_devices("auto")
        print("âœ… TensorFlow ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ TensorFlow ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

    return True


def test_csv_loading():
    """CSV ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print_section("TEST 2: CSV ë°ì´í„°ì…‹ ë¡œë”©")

    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {DEFAULT_TEST_DATA_DIR}")

    try:
        datasets = _iter_csv_datasets(DEFAULT_TEST_DATA_DIR)

        if not datasets:
            print("âŒ ë¡œë“œëœ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤")
            return False, None

        print(f"âœ… {len(datasets)}ê°œ ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ\n")

        # ê° ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥
        for i, ds in enumerate(datasets, 1):
            print(f"{i}. {ds['csv_name']}")
            print(f"   - ì‚°ì—…: {ds['industry']}")
            print(f"   - ê³µì •: {ds['process']}")
            print(f"   - ë¼ì¸ ì»¬ëŸ¼: {ds['line']}")
            print(f"   - ë©”íŠ¸ë¦­ ê°œìˆ˜: {len(ds['metric_cols'])}")
            print(f"   - ë°ì´í„° í–‰ ìˆ˜: {len(ds['data'])}")

        return True, datasets

    except Exception as e:
        print(f"âŒ CSV ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_model_loading(datasets):
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print_section("TEST 3: ì´ìƒì¹˜ íƒì§€ ëª¨ë¸ ë¡œë”©")

    if not datasets:
        print("âš ï¸  ë°ì´í„°ì…‹ì´ ì—†ì–´ ëª¨ë¸ ë¡œë”© ìŠ¤í‚µ")
        return False, None

    print(f"ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {DEFAULT_MODELS_ROOT}")

    try:
        anomaly_models = build_anomaly_registry_from_root(DEFAULT_MODELS_ROOT, datasets)

        if not anomaly_models:
            print("âš ï¸  ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
            return False, None

        print(f"âœ… {len(anomaly_models)}ê°œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ\n")

        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        for csv_name in anomaly_models.keys():
            print(f"  - {csv_name}: ëª¨ë¸ í•¨ìˆ˜ ë“±ë¡ë¨")

        return True, anomaly_models

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_anomaly_detection(datasets, anomaly_models):
    """ì´ìƒì¹˜ íƒì§€ í•¨ìˆ˜ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
    print_section("TEST 4: ì´ìƒì¹˜ íƒì§€ ì‹¤í–‰")

    if not datasets or not anomaly_models:
        print("âš ï¸  ë°ì´í„°ì…‹ ë˜ëŠ” ëª¨ë¸ì´ ì—†ì–´ ì´ìƒì¹˜ íƒì§€ ìŠ¤í‚µ")
        return False

    success_count = 0
    fail_count = 0

    # ê° ë°ì´í„°ì…‹ì˜ ì²« ë²ˆì§¸ í–‰ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    for ds in datasets:
        csv_name = ds["csv_name"]

        if csv_name not in anomaly_models:
            continue

        anomaly_fn = anomaly_models[csv_name]
        df = ds["data"]

        if len(df) == 0:
            continue

        # ì²« ë²ˆì§¸ í–‰ í…ŒìŠ¤íŠ¸
        row = df.iloc[0]

        try:
            result = anomaly_fn(row)

            print(f"\nğŸ“Š {csv_name}:")
            print(f"   - ëª¨ë¸: {result.get('model')}")
            print(f"   - ì ìˆ˜: {result.get('score'):.6f}")
            print(f"   - ì„ê³„ê°’: {result.get('threshold'):.6f}")
            print(f"   - ì´ìƒì¹˜ ì—¬ë¶€: {result.get('is_anomaly')}")

            success_count += 1

        except Exception as e:
            print(f"\nâŒ {csv_name} ì´ìƒì¹˜ íƒì§€ ì‹¤íŒ¨: {e}")
            fail_count += 1

    print(f"\nâœ… ì„±ê³µ: {success_count}ê°œ")
    if fail_count > 0:
        print(f"âŒ ì‹¤íŒ¨: {fail_count}ê°œ")

    return success_count > 0


def test_state_resolution(datasets):
    """ìƒíƒœ resolver í…ŒìŠ¤íŠ¸"""
    print_section("TEST 5: ê³µì • ìƒíƒœ ì¶”ë¡ ")

    if not datasets:
        print("âš ï¸  ë°ì´í„°ì…‹ì´ ì—†ì–´ ìƒíƒœ ì¶”ë¡  ìŠ¤í‚µ")
        return False

    # ì²« ë²ˆì§¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    ds = datasets[0]
    df = ds["data"]

    if len(df) == 0:
        print("âš ï¸  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False

    row = df.iloc[0]

    try:
        state = _resolve_state(row, default_state_fn, list(df.columns))
        print(f"âœ… ìƒíƒœ ì¶”ë¡  ì„±ê³µ: {state}")
        print(f"   - ë°ì´í„°ì…‹: {ds['csv_name']}")
        print(f"   - ì²« í–‰ ë°ì´í„°: {dict(row[:5])}")

        return True

    except Exception as e:
        print(f"âŒ ìƒíƒœ ì¶”ë¡  ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_conversion(datasets):
    """ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸"""
    print_section("TEST 6: ë°ì´í„° ë³€í™˜ ìœ í‹¸ë¦¬í‹°")

    if not datasets:
        print("âš ï¸  ë°ì´í„°ì…‹ì´ ì—†ì–´ ë³€í™˜ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
        return False

    ds = datasets[0]
    df = ds["data"]

    if len(df) == 0:
        print("âš ï¸  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False

    row = df.iloc[0]

    try:
        # ê° ì»¬ëŸ¼ ê°’ì„ Python ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜
        for col in list(row.index)[:5]:  # ì²˜ìŒ 5ê°œ ì»¬ëŸ¼ë§Œ í…ŒìŠ¤íŠ¸
            original = row[col]
            converted = _to_python_scalar(original)
            print(f"  {col}: {type(original).__name__} â†’ {type(converted).__name__} ({converted})")

        print("âœ… ë°ì´í„° ë³€í™˜ ì„±ê³µ")
        return True

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "ğŸ”¬" * 30)
    print("  DASHBOARD.PY ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ğŸ”¬" * 30)

    results = {}

    # TEST 1: TensorFlow ë””ë°”ì´ìŠ¤ ì´ˆê¸°í™”
    results["tf_device"] = test_tf_device_init()

    # TEST 2: CSV ë¡œë”©
    csv_success, datasets = test_csv_loading()
    results["csv_loading"] = csv_success

    # TEST 3: ëª¨ë¸ ë¡œë”©
    model_success, anomaly_models = test_model_loading(datasets)
    results["model_loading"] = model_success

    # TEST 4: ì´ìƒì¹˜ íƒì§€
    results["anomaly_detection"] = test_anomaly_detection(datasets, anomaly_models)

    # TEST 5: ìƒíƒœ ì¶”ë¡ 
    results["state_resolution"] = test_state_resolution(datasets)

    # TEST 6: ë°ì´í„° ë³€í™˜
    results["data_conversion"] = test_data_conversion(datasets)

    # ê²°ê³¼ ìš”ì•½
    print_section("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")

    passed = sum(1 for v in results.values() if v)
    total = len(results)

    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {test_name}")

    print(f"\nì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼")

    if passed == total:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)
